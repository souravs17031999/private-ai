{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_federated_learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/souravs17031999/private-ai/blob/master/Final_federated_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEGm3FrOVHZG",
        "colab_type": "text"
      },
      "source": [
        "# PROJECT - XII\n",
        "\n",
        "## OBJECTIVE : IMPLEMENTING FEDERATED LEARNING ON MNIST DATASET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFN4gscSVWWe",
        "colab_type": "text"
      },
      "source": [
        "We have already implmented federated learning on toy dataset , now it's time for some real applications.\n",
        "Let's first install pysyft."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJwunSdESo9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install syft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6RDMH2cVkiw",
        "colab_type": "text"
      },
      "source": [
        "Start by importing all packages required for torch and pysyft"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCQ-Fu9aT7c5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQuucJp_UxwY",
        "colab_type": "code",
        "outputId": "e2f9f4d4-5928-4b65-a8dc-ec130b8c0b5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "import syft as sy\n",
        "hook = sy.TorchHook(torch)\n",
        "# let's create two virtual workers who will hold the data while training the model locally\n",
        "bob = sy.VirtualWorker(hook, id = \"bob\")\n",
        "alice = sy.VirtualWorker(hook, id = \"alice\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0711 04:42:56.079641 139812741711744 secure_random.py:26] Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/usr/local/lib/python3.6/dist-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.14.0.so'\n",
            "W0711 04:42:56.095262 139812741711744 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tf_encrypted/session.py:26: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2u_R9O84jgH7",
        "colab_type": "text"
      },
      "source": [
        "It's time to load the data and apply our transforms !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNK0828jhcNj",
        "colab_type": "text"
      },
      "source": [
        "We first load the data and transform the training Dataset into a Federated Dataset using the .federate method: it splits the dataset in two parts and send them to the workers alice and bob. This federated dataset is now given to a Federated DataLoader which will iterate over remote batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er5u9ZG1ZvpW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Arguments():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 64\n",
        "        self.test_batch_size = 1000\n",
        "        self.epochs = 10\n",
        "        self.lr = 0.01\n",
        "        self.momentum = 0.5\n",
        "        self.no_cuda = False\n",
        "        self.seed = 1\n",
        "        self.log_interval = 10\n",
        "        self.save_model = False\n",
        "\n",
        "args = Arguments()\n",
        "\n",
        "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2JeGrfzVEW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "federated_train_loader = sy.FederatedDataLoader( # <-- this is now a FederatedDataLoader \n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ]))\n",
        "    .federate((bob, alice)), # <-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset\n",
        "    batch_size=args.batch_size, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.1307,), (0.3081,))\n",
        "                   ])),\n",
        "    batch_size=args.test_batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ2XHwKnknsJ",
        "colab_type": "code",
        "outputId": "094a63ca-8bf0-4418-fcbc-4f05a5e4c46c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(test_loader)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "157"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuny2RkGi4Zf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "        self.fc1 = nn.Linear(4*4*50, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4*4*50)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyzqIFxRmygL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(args, model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(federated_train_loader): # <-- now it is a distributed dataset\n",
        "        model.send(data.location) # <-- NEW: send the model to the right location\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        model.get() # <-- NEW: get the model back\n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            loss = loss.get() # <-- NEW: get the loss back\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * args.batch_size, len(train_loader) * args.batch_size, #batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAMtt150Xdww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(args, model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability \n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e80Hqd33Xfw7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "29386387-55c2-4da0-a532-e2465a199346"
      },
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment\n",
        "\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    train(args, model, device, federated_train_loader, optimizer, epoch)\n",
        "    test(args, model, device, test_loader)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60032 (0%)]\tLoss: 2.307303\n",
            "Train Epoch: 1 [640/60032 (1%)]\tLoss: 2.311168\n",
            "Train Epoch: 1 [1280/60032 (2%)]\tLoss: 2.192290\n",
            "Train Epoch: 1 [1920/60032 (3%)]\tLoss: 2.152380\n",
            "Train Epoch: 1 [2560/60032 (4%)]\tLoss: 2.086846\n",
            "Train Epoch: 1 [3200/60032 (5%)]\tLoss: 1.989702\n",
            "Train Epoch: 1 [3840/60032 (6%)]\tLoss: 1.851289\n",
            "Train Epoch: 1 [4480/60032 (7%)]\tLoss: 1.685259\n",
            "Train Epoch: 1 [5120/60032 (9%)]\tLoss: 1.537941\n",
            "Train Epoch: 1 [5760/60032 (10%)]\tLoss: 1.258122\n",
            "Train Epoch: 1 [6400/60032 (11%)]\tLoss: 1.041625\n",
            "Train Epoch: 1 [7040/60032 (12%)]\tLoss: 0.869986\n",
            "Train Epoch: 1 [7680/60032 (13%)]\tLoss: 0.786288\n",
            "Train Epoch: 1 [8320/60032 (14%)]\tLoss: 0.612632\n",
            "Train Epoch: 1 [8960/60032 (15%)]\tLoss: 0.466813\n",
            "Train Epoch: 1 [9600/60032 (16%)]\tLoss: 0.752732\n",
            "Train Epoch: 1 [10240/60032 (17%)]\tLoss: 0.530697\n",
            "Train Epoch: 1 [10880/60032 (18%)]\tLoss: 0.524642\n",
            "Train Epoch: 1 [11520/60032 (19%)]\tLoss: 0.389656\n",
            "Train Epoch: 1 [12160/60032 (20%)]\tLoss: 0.659216\n",
            "Train Epoch: 1 [12800/60032 (21%)]\tLoss: 0.469157\n",
            "Train Epoch: 1 [13440/60032 (22%)]\tLoss: 0.668357\n",
            "Train Epoch: 1 [14080/60032 (23%)]\tLoss: 0.605123\n",
            "Train Epoch: 1 [14720/60032 (25%)]\tLoss: 0.515602\n",
            "Train Epoch: 1 [15360/60032 (26%)]\tLoss: 0.555904\n",
            "Train Epoch: 1 [16000/60032 (27%)]\tLoss: 0.425490\n",
            "Train Epoch: 1 [16640/60032 (28%)]\tLoss: 0.419756\n",
            "Train Epoch: 1 [17280/60032 (29%)]\tLoss: 0.298107\n",
            "Train Epoch: 1 [17920/60032 (30%)]\tLoss: 0.388610\n",
            "Train Epoch: 1 [18560/60032 (31%)]\tLoss: 0.596739\n",
            "Train Epoch: 1 [19200/60032 (32%)]\tLoss: 0.709352\n",
            "Train Epoch: 1 [19840/60032 (33%)]\tLoss: 0.400513\n",
            "Train Epoch: 1 [20480/60032 (34%)]\tLoss: 0.290152\n",
            "Train Epoch: 1 [21120/60032 (35%)]\tLoss: 0.242563\n",
            "Train Epoch: 1 [21760/60032 (36%)]\tLoss: 0.323986\n",
            "Train Epoch: 1 [22400/60032 (37%)]\tLoss: 0.328781\n",
            "Train Epoch: 1 [23040/60032 (38%)]\tLoss: 0.295998\n",
            "Train Epoch: 1 [23680/60032 (39%)]\tLoss: 0.397035\n",
            "Train Epoch: 1 [24320/60032 (41%)]\tLoss: 0.384348\n",
            "Train Epoch: 1 [24960/60032 (42%)]\tLoss: 0.438596\n",
            "Train Epoch: 1 [25600/60032 (43%)]\tLoss: 0.494415\n",
            "Train Epoch: 1 [26240/60032 (44%)]\tLoss: 0.169124\n",
            "Train Epoch: 1 [26880/60032 (45%)]\tLoss: 0.444474\n",
            "Train Epoch: 1 [27520/60032 (46%)]\tLoss: 0.252036\n",
            "Train Epoch: 1 [28160/60032 (47%)]\tLoss: 0.326689\n",
            "Train Epoch: 1 [28800/60032 (48%)]\tLoss: 0.463548\n",
            "Train Epoch: 1 [29440/60032 (49%)]\tLoss: 0.321815\n",
            "Train Epoch: 1 [30080/60032 (50%)]\tLoss: 0.295110\n",
            "Train Epoch: 1 [30720/60032 (51%)]\tLoss: 0.376724\n",
            "Train Epoch: 1 [31360/60032 (52%)]\tLoss: 0.242428\n",
            "Train Epoch: 1 [32000/60032 (53%)]\tLoss: 0.364026\n",
            "Train Epoch: 1 [32640/60032 (54%)]\tLoss: 0.231174\n",
            "Train Epoch: 1 [33280/60032 (55%)]\tLoss: 0.074873\n",
            "Train Epoch: 1 [33920/60032 (57%)]\tLoss: 0.374032\n",
            "Train Epoch: 1 [34560/60032 (58%)]\tLoss: 0.164069\n",
            "Train Epoch: 1 [35200/60032 (59%)]\tLoss: 0.212245\n",
            "Train Epoch: 1 [35840/60032 (60%)]\tLoss: 0.372821\n",
            "Train Epoch: 1 [36480/60032 (61%)]\tLoss: 0.186278\n",
            "Train Epoch: 1 [37120/60032 (62%)]\tLoss: 0.297977\n",
            "Train Epoch: 1 [37760/60032 (63%)]\tLoss: 0.360549\n",
            "Train Epoch: 1 [38400/60032 (64%)]\tLoss: 0.267768\n",
            "Train Epoch: 1 [39040/60032 (65%)]\tLoss: 0.276794\n",
            "Train Epoch: 1 [39680/60032 (66%)]\tLoss: 0.255412\n",
            "Train Epoch: 1 [40320/60032 (67%)]\tLoss: 0.161879\n",
            "Train Epoch: 1 [40960/60032 (68%)]\tLoss: 0.179464\n",
            "Train Epoch: 1 [41600/60032 (69%)]\tLoss: 0.131240\n",
            "Train Epoch: 1 [42240/60032 (70%)]\tLoss: 0.222902\n",
            "Train Epoch: 1 [42880/60032 (71%)]\tLoss: 0.272309\n",
            "Train Epoch: 1 [43520/60032 (72%)]\tLoss: 0.104952\n",
            "Train Epoch: 1 [44160/60032 (74%)]\tLoss: 0.181311\n",
            "Train Epoch: 1 [44800/60032 (75%)]\tLoss: 0.122301\n",
            "Train Epoch: 1 [45440/60032 (76%)]\tLoss: 0.247824\n",
            "Train Epoch: 1 [46080/60032 (77%)]\tLoss: 0.177838\n",
            "Train Epoch: 1 [46720/60032 (78%)]\tLoss: 0.327867\n",
            "Train Epoch: 1 [47360/60032 (79%)]\tLoss: 0.095358\n",
            "Train Epoch: 1 [48000/60032 (80%)]\tLoss: 0.135685\n",
            "Train Epoch: 1 [48640/60032 (81%)]\tLoss: 0.304475\n",
            "Train Epoch: 1 [49280/60032 (82%)]\tLoss: 0.117748\n",
            "Train Epoch: 1 [49920/60032 (83%)]\tLoss: 0.146991\n",
            "Train Epoch: 1 [50560/60032 (84%)]\tLoss: 0.284655\n",
            "Train Epoch: 1 [51200/60032 (85%)]\tLoss: 0.117519\n",
            "Train Epoch: 1 [51840/60032 (86%)]\tLoss: 0.195316\n",
            "Train Epoch: 1 [52480/60032 (87%)]\tLoss: 0.131069\n",
            "Train Epoch: 1 [53120/60032 (88%)]\tLoss: 0.198428\n",
            "Train Epoch: 1 [53760/60032 (90%)]\tLoss: 0.310176\n",
            "Train Epoch: 1 [54400/60032 (91%)]\tLoss: 0.157669\n",
            "Train Epoch: 1 [55040/60032 (92%)]\tLoss: 0.150337\n",
            "Train Epoch: 1 [55680/60032 (93%)]\tLoss: 0.128236\n",
            "Train Epoch: 1 [56320/60032 (94%)]\tLoss: 0.265189\n",
            "Train Epoch: 1 [56960/60032 (95%)]\tLoss: 0.132432\n",
            "Train Epoch: 1 [57600/60032 (96%)]\tLoss: 0.145601\n",
            "Train Epoch: 1 [58240/60032 (97%)]\tLoss: 0.110224\n",
            "Train Epoch: 1 [58880/60032 (98%)]\tLoss: 0.351000\n",
            "Train Epoch: 1 [59520/60032 (99%)]\tLoss: 0.104552\n",
            "\n",
            "Test set: Average loss: 0.1697, Accuracy: 9482/10000 (95%)\n",
            "\n",
            "Train Epoch: 2 [0/60032 (0%)]\tLoss: 0.108783\n",
            "Train Epoch: 2 [640/60032 (1%)]\tLoss: 0.130634\n",
            "Train Epoch: 2 [1280/60032 (2%)]\tLoss: 0.178844\n",
            "Train Epoch: 2 [1920/60032 (3%)]\tLoss: 0.268409\n",
            "Train Epoch: 2 [2560/60032 (4%)]\tLoss: 0.361400\n",
            "Train Epoch: 2 [3200/60032 (5%)]\tLoss: 0.174303\n",
            "Train Epoch: 2 [3840/60032 (6%)]\tLoss: 0.050407\n",
            "Train Epoch: 2 [4480/60032 (7%)]\tLoss: 0.233794\n",
            "Train Epoch: 2 [5120/60032 (9%)]\tLoss: 0.167950\n",
            "Train Epoch: 2 [5760/60032 (10%)]\tLoss: 0.288707\n",
            "Train Epoch: 2 [6400/60032 (11%)]\tLoss: 0.159134\n",
            "Train Epoch: 2 [7040/60032 (12%)]\tLoss: 0.049571\n",
            "Train Epoch: 2 [7680/60032 (13%)]\tLoss: 0.164504\n",
            "Train Epoch: 2 [8320/60032 (14%)]\tLoss: 0.113360\n",
            "Train Epoch: 2 [8960/60032 (15%)]\tLoss: 0.160040\n",
            "Train Epoch: 2 [9600/60032 (16%)]\tLoss: 0.207120\n",
            "Train Epoch: 2 [10240/60032 (17%)]\tLoss: 0.206982\n",
            "Train Epoch: 2 [10880/60032 (18%)]\tLoss: 0.133462\n",
            "Train Epoch: 2 [11520/60032 (19%)]\tLoss: 0.149142\n",
            "Train Epoch: 2 [12160/60032 (20%)]\tLoss: 0.141327\n",
            "Train Epoch: 2 [12800/60032 (21%)]\tLoss: 0.123151\n",
            "Train Epoch: 2 [13440/60032 (22%)]\tLoss: 0.148193\n",
            "Train Epoch: 2 [14080/60032 (23%)]\tLoss: 0.166902\n",
            "Train Epoch: 2 [14720/60032 (25%)]\tLoss: 0.160620\n",
            "Train Epoch: 2 [15360/60032 (26%)]\tLoss: 0.127323\n",
            "Train Epoch: 2 [16000/60032 (27%)]\tLoss: 0.126059\n",
            "Train Epoch: 2 [16640/60032 (28%)]\tLoss: 0.105936\n",
            "Train Epoch: 2 [17280/60032 (29%)]\tLoss: 0.166551\n",
            "Train Epoch: 2 [17920/60032 (30%)]\tLoss: 0.188717\n",
            "Train Epoch: 2 [18560/60032 (31%)]\tLoss: 0.225595\n",
            "Train Epoch: 2 [19200/60032 (32%)]\tLoss: 0.272820\n",
            "Train Epoch: 2 [19840/60032 (33%)]\tLoss: 0.040218\n",
            "Train Epoch: 2 [20480/60032 (34%)]\tLoss: 0.134691\n",
            "Train Epoch: 2 [21120/60032 (35%)]\tLoss: 0.069016\n",
            "Train Epoch: 2 [21760/60032 (36%)]\tLoss: 0.072795\n",
            "Train Epoch: 2 [22400/60032 (37%)]\tLoss: 0.077605\n",
            "Train Epoch: 2 [23040/60032 (38%)]\tLoss: 0.108389\n",
            "Train Epoch: 2 [23680/60032 (39%)]\tLoss: 0.095485\n",
            "Train Epoch: 2 [24320/60032 (41%)]\tLoss: 0.168236\n",
            "Train Epoch: 2 [24960/60032 (42%)]\tLoss: 0.223275\n",
            "Train Epoch: 2 [25600/60032 (43%)]\tLoss: 0.128605\n",
            "Train Epoch: 2 [26240/60032 (44%)]\tLoss: 0.084433\n",
            "Train Epoch: 2 [26880/60032 (45%)]\tLoss: 0.168890\n",
            "Train Epoch: 2 [27520/60032 (46%)]\tLoss: 0.265549\n",
            "Train Epoch: 2 [28160/60032 (47%)]\tLoss: 0.130930\n",
            "Train Epoch: 2 [28800/60032 (48%)]\tLoss: 0.165612\n",
            "Train Epoch: 2 [29440/60032 (49%)]\tLoss: 0.089506\n",
            "Train Epoch: 2 [30080/60032 (50%)]\tLoss: 0.138641\n",
            "Train Epoch: 2 [30720/60032 (51%)]\tLoss: 0.173843\n",
            "Train Epoch: 2 [31360/60032 (52%)]\tLoss: 0.110678\n",
            "Train Epoch: 2 [32000/60032 (53%)]\tLoss: 0.111028\n",
            "Train Epoch: 2 [32640/60032 (54%)]\tLoss: 0.083697\n",
            "Train Epoch: 2 [33280/60032 (55%)]\tLoss: 0.071565\n",
            "Train Epoch: 2 [33920/60032 (57%)]\tLoss: 0.097270\n",
            "Train Epoch: 2 [34560/60032 (58%)]\tLoss: 0.092637\n",
            "Train Epoch: 2 [35200/60032 (59%)]\tLoss: 0.075118\n",
            "Train Epoch: 2 [35840/60032 (60%)]\tLoss: 0.151536\n",
            "Train Epoch: 2 [36480/60032 (61%)]\tLoss: 0.114903\n",
            "Train Epoch: 2 [37120/60032 (62%)]\tLoss: 0.044861\n",
            "Train Epoch: 2 [37760/60032 (63%)]\tLoss: 0.092158\n",
            "Train Epoch: 2 [38400/60032 (64%)]\tLoss: 0.050626\n",
            "Train Epoch: 2 [39040/60032 (65%)]\tLoss: 0.064558\n",
            "Train Epoch: 2 [39680/60032 (66%)]\tLoss: 0.030760\n",
            "Train Epoch: 2 [40320/60032 (67%)]\tLoss: 0.097743\n",
            "Train Epoch: 2 [40960/60032 (68%)]\tLoss: 0.120120\n",
            "Train Epoch: 2 [41600/60032 (69%)]\tLoss: 0.182141\n",
            "Train Epoch: 2 [42240/60032 (70%)]\tLoss: 0.214443\n",
            "Train Epoch: 2 [42880/60032 (71%)]\tLoss: 0.207327\n",
            "Train Epoch: 2 [43520/60032 (72%)]\tLoss: 0.067606\n",
            "Train Epoch: 2 [44160/60032 (74%)]\tLoss: 0.094947\n",
            "Train Epoch: 2 [44800/60032 (75%)]\tLoss: 0.203161\n",
            "Train Epoch: 2 [45440/60032 (76%)]\tLoss: 0.111636\n",
            "Train Epoch: 2 [46080/60032 (77%)]\tLoss: 0.134852\n",
            "Train Epoch: 2 [46720/60032 (78%)]\tLoss: 0.092848\n",
            "Train Epoch: 2 [47360/60032 (79%)]\tLoss: 0.213494\n",
            "Train Epoch: 2 [48000/60032 (80%)]\tLoss: 0.162303\n",
            "Train Epoch: 2 [48640/60032 (81%)]\tLoss: 0.164103\n",
            "Train Epoch: 2 [49280/60032 (82%)]\tLoss: 0.029431\n",
            "Train Epoch: 2 [49920/60032 (83%)]\tLoss: 0.036252\n",
            "Train Epoch: 2 [50560/60032 (84%)]\tLoss: 0.180452\n",
            "Train Epoch: 2 [51200/60032 (85%)]\tLoss: 0.086417\n",
            "Train Epoch: 2 [51840/60032 (86%)]\tLoss: 0.086221\n",
            "Train Epoch: 2 [52480/60032 (87%)]\tLoss: 0.154273\n",
            "Train Epoch: 2 [53120/60032 (88%)]\tLoss: 0.157564\n",
            "Train Epoch: 2 [53760/60032 (90%)]\tLoss: 0.041230\n",
            "Train Epoch: 2 [54400/60032 (91%)]\tLoss: 0.092966\n",
            "Train Epoch: 2 [55040/60032 (92%)]\tLoss: 0.065840\n",
            "Train Epoch: 2 [55680/60032 (93%)]\tLoss: 0.201394\n",
            "Train Epoch: 2 [56320/60032 (94%)]\tLoss: 0.052815\n",
            "Train Epoch: 2 [56960/60032 (95%)]\tLoss: 0.122595\n",
            "Train Epoch: 2 [57600/60032 (96%)]\tLoss: 0.041994\n",
            "Train Epoch: 2 [58240/60032 (97%)]\tLoss: 0.071899\n",
            "Train Epoch: 2 [58880/60032 (98%)]\tLoss: 0.080757\n",
            "Train Epoch: 2 [59520/60032 (99%)]\tLoss: 0.109643\n",
            "\n",
            "Test set: Average loss: 0.0884, Accuracy: 9742/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60032 (0%)]\tLoss: 0.047257\n",
            "Train Epoch: 3 [640/60032 (1%)]\tLoss: 0.140460\n",
            "Train Epoch: 3 [1280/60032 (2%)]\tLoss: 0.146409\n",
            "Train Epoch: 3 [1920/60032 (3%)]\tLoss: 0.149526\n",
            "Train Epoch: 3 [2560/60032 (4%)]\tLoss: 0.121334\n",
            "Train Epoch: 3 [3200/60032 (5%)]\tLoss: 0.036404\n",
            "Train Epoch: 3 [3840/60032 (6%)]\tLoss: 0.050029\n",
            "Train Epoch: 3 [4480/60032 (7%)]\tLoss: 0.133077\n",
            "Train Epoch: 3 [5120/60032 (9%)]\tLoss: 0.058191\n",
            "Train Epoch: 3 [5760/60032 (10%)]\tLoss: 0.047797\n",
            "Train Epoch: 3 [6400/60032 (11%)]\tLoss: 0.157703\n",
            "Train Epoch: 3 [7040/60032 (12%)]\tLoss: 0.066190\n",
            "Train Epoch: 3 [7680/60032 (13%)]\tLoss: 0.101928\n",
            "Train Epoch: 3 [8320/60032 (14%)]\tLoss: 0.119930\n",
            "Train Epoch: 3 [8960/60032 (15%)]\tLoss: 0.089864\n",
            "Train Epoch: 3 [9600/60032 (16%)]\tLoss: 0.075618\n",
            "Train Epoch: 3 [10240/60032 (17%)]\tLoss: 0.156778\n",
            "Train Epoch: 3 [10880/60032 (18%)]\tLoss: 0.064137\n",
            "Train Epoch: 3 [11520/60032 (19%)]\tLoss: 0.092070\n",
            "Train Epoch: 3 [12160/60032 (20%)]\tLoss: 0.060145\n",
            "Train Epoch: 3 [12800/60032 (21%)]\tLoss: 0.123429\n",
            "Train Epoch: 3 [13440/60032 (22%)]\tLoss: 0.208207\n",
            "Train Epoch: 3 [14080/60032 (23%)]\tLoss: 0.202319\n",
            "Train Epoch: 3 [14720/60032 (25%)]\tLoss: 0.080600\n",
            "Train Epoch: 3 [15360/60032 (26%)]\tLoss: 0.102707\n",
            "Train Epoch: 3 [16000/60032 (27%)]\tLoss: 0.055917\n",
            "Train Epoch: 3 [16640/60032 (28%)]\tLoss: 0.232415\n",
            "Train Epoch: 3 [17280/60032 (29%)]\tLoss: 0.013715\n",
            "Train Epoch: 3 [17920/60032 (30%)]\tLoss: 0.174621\n",
            "Train Epoch: 3 [18560/60032 (31%)]\tLoss: 0.051066\n",
            "Train Epoch: 3 [19200/60032 (32%)]\tLoss: 0.124666\n",
            "Train Epoch: 3 [19840/60032 (33%)]\tLoss: 0.088420\n",
            "Train Epoch: 3 [20480/60032 (34%)]\tLoss: 0.023159\n",
            "Train Epoch: 3 [21120/60032 (35%)]\tLoss: 0.166623\n",
            "Train Epoch: 3 [21760/60032 (36%)]\tLoss: 0.034567\n",
            "Train Epoch: 3 [22400/60032 (37%)]\tLoss: 0.173968\n",
            "Train Epoch: 3 [23040/60032 (38%)]\tLoss: 0.103648\n",
            "Train Epoch: 3 [23680/60032 (39%)]\tLoss: 0.061427\n",
            "Train Epoch: 3 [24320/60032 (41%)]\tLoss: 0.048621\n",
            "Train Epoch: 3 [24960/60032 (42%)]\tLoss: 0.045386\n",
            "Train Epoch: 3 [25600/60032 (43%)]\tLoss: 0.067170\n",
            "Train Epoch: 3 [26240/60032 (44%)]\tLoss: 0.128312\n",
            "Train Epoch: 3 [26880/60032 (45%)]\tLoss: 0.080391\n",
            "Train Epoch: 3 [27520/60032 (46%)]\tLoss: 0.109958\n",
            "Train Epoch: 3 [28160/60032 (47%)]\tLoss: 0.019351\n",
            "Train Epoch: 3 [28800/60032 (48%)]\tLoss: 0.058486\n",
            "Train Epoch: 3 [29440/60032 (49%)]\tLoss: 0.099657\n",
            "Train Epoch: 3 [30080/60032 (50%)]\tLoss: 0.097506\n",
            "Train Epoch: 3 [30720/60032 (51%)]\tLoss: 0.162841\n",
            "Train Epoch: 3 [31360/60032 (52%)]\tLoss: 0.063709\n",
            "Train Epoch: 3 [32000/60032 (53%)]\tLoss: 0.212804\n",
            "Train Epoch: 3 [32640/60032 (54%)]\tLoss: 0.067807\n",
            "Train Epoch: 3 [33280/60032 (55%)]\tLoss: 0.062049\n",
            "Train Epoch: 3 [33920/60032 (57%)]\tLoss: 0.076133\n",
            "Train Epoch: 3 [34560/60032 (58%)]\tLoss: 0.038513\n",
            "Train Epoch: 3 [35200/60032 (59%)]\tLoss: 0.028283\n",
            "Train Epoch: 3 [35840/60032 (60%)]\tLoss: 0.063695\n",
            "Train Epoch: 3 [36480/60032 (61%)]\tLoss: 0.075123\n",
            "Train Epoch: 3 [37120/60032 (62%)]\tLoss: 0.169328\n",
            "Train Epoch: 3 [37760/60032 (63%)]\tLoss: 0.244086\n",
            "Train Epoch: 3 [38400/60032 (64%)]\tLoss: 0.059487\n",
            "Train Epoch: 3 [39040/60032 (65%)]\tLoss: 0.137210\n",
            "Train Epoch: 3 [39680/60032 (66%)]\tLoss: 0.114308\n",
            "Train Epoch: 3 [40320/60032 (67%)]\tLoss: 0.121784\n",
            "Train Epoch: 3 [40960/60032 (68%)]\tLoss: 0.105202\n",
            "Train Epoch: 3 [41600/60032 (69%)]\tLoss: 0.100564\n",
            "Train Epoch: 3 [42240/60032 (70%)]\tLoss: 0.034195\n",
            "Train Epoch: 3 [42880/60032 (71%)]\tLoss: 0.043786\n",
            "Train Epoch: 3 [43520/60032 (72%)]\tLoss: 0.122731\n",
            "Train Epoch: 3 [44160/60032 (74%)]\tLoss: 0.073052\n",
            "Train Epoch: 3 [44800/60032 (75%)]\tLoss: 0.036664\n",
            "Train Epoch: 3 [45440/60032 (76%)]\tLoss: 0.023622\n",
            "Train Epoch: 3 [46080/60032 (77%)]\tLoss: 0.088265\n",
            "Train Epoch: 3 [46720/60032 (78%)]\tLoss: 0.027356\n",
            "Train Epoch: 3 [47360/60032 (79%)]\tLoss: 0.068574\n",
            "Train Epoch: 3 [48000/60032 (80%)]\tLoss: 0.069292\n",
            "Train Epoch: 3 [48640/60032 (81%)]\tLoss: 0.135589\n",
            "Train Epoch: 3 [49280/60032 (82%)]\tLoss: 0.142586\n",
            "Train Epoch: 3 [49920/60032 (83%)]\tLoss: 0.198174\n",
            "Train Epoch: 3 [50560/60032 (84%)]\tLoss: 0.021664\n",
            "Train Epoch: 3 [51200/60032 (85%)]\tLoss: 0.044627\n",
            "Train Epoch: 3 [51840/60032 (86%)]\tLoss: 0.086133\n",
            "Train Epoch: 3 [52480/60032 (87%)]\tLoss: 0.047954\n",
            "Train Epoch: 3 [53120/60032 (88%)]\tLoss: 0.009614\n",
            "Train Epoch: 3 [53760/60032 (90%)]\tLoss: 0.042496\n",
            "Train Epoch: 3 [54400/60032 (91%)]\tLoss: 0.113195\n",
            "Train Epoch: 3 [55040/60032 (92%)]\tLoss: 0.084884\n",
            "Train Epoch: 3 [55680/60032 (93%)]\tLoss: 0.031776\n",
            "Train Epoch: 3 [56320/60032 (94%)]\tLoss: 0.018655\n",
            "Train Epoch: 3 [56960/60032 (95%)]\tLoss: 0.026237\n",
            "Train Epoch: 3 [57600/60032 (96%)]\tLoss: 0.022467\n",
            "Train Epoch: 3 [58240/60032 (97%)]\tLoss: 0.056864\n",
            "Train Epoch: 3 [58880/60032 (98%)]\tLoss: 0.022499\n",
            "Train Epoch: 3 [59520/60032 (99%)]\tLoss: 0.008545\n",
            "\n",
            "Test set: Average loss: 0.0658, Accuracy: 9802/10000 (98%)\n",
            "\n",
            "Train Epoch: 4 [0/60032 (0%)]\tLoss: 0.142910\n",
            "Train Epoch: 4 [640/60032 (1%)]\tLoss: 0.037667\n",
            "Train Epoch: 4 [1280/60032 (2%)]\tLoss: 0.074579\n",
            "Train Epoch: 4 [1920/60032 (3%)]\tLoss: 0.013535\n",
            "Train Epoch: 4 [2560/60032 (4%)]\tLoss: 0.061266\n",
            "Train Epoch: 4 [3200/60032 (5%)]\tLoss: 0.091308\n",
            "Train Epoch: 4 [3840/60032 (6%)]\tLoss: 0.060359\n",
            "Train Epoch: 4 [4480/60032 (7%)]\tLoss: 0.249359\n",
            "Train Epoch: 4 [5120/60032 (9%)]\tLoss: 0.114548\n",
            "Train Epoch: 4 [5760/60032 (10%)]\tLoss: 0.040352\n",
            "Train Epoch: 4 [6400/60032 (11%)]\tLoss: 0.091226\n",
            "Train Epoch: 4 [7040/60032 (12%)]\tLoss: 0.203067\n",
            "Train Epoch: 4 [7680/60032 (13%)]\tLoss: 0.110228\n",
            "Train Epoch: 4 [8320/60032 (14%)]\tLoss: 0.036488\n",
            "Train Epoch: 4 [8960/60032 (15%)]\tLoss: 0.076680\n",
            "Train Epoch: 4 [9600/60032 (16%)]\tLoss: 0.063273\n",
            "Train Epoch: 4 [10240/60032 (17%)]\tLoss: 0.209754\n",
            "Train Epoch: 4 [10880/60032 (18%)]\tLoss: 0.146369\n",
            "Train Epoch: 4 [11520/60032 (19%)]\tLoss: 0.137006\n",
            "Train Epoch: 4 [12160/60032 (20%)]\tLoss: 0.091364\n",
            "Train Epoch: 4 [12800/60032 (21%)]\tLoss: 0.120077\n",
            "Train Epoch: 4 [13440/60032 (22%)]\tLoss: 0.070486\n",
            "Train Epoch: 4 [14080/60032 (23%)]\tLoss: 0.099413\n",
            "Train Epoch: 4 [14720/60032 (25%)]\tLoss: 0.042255\n",
            "Train Epoch: 4 [15360/60032 (26%)]\tLoss: 0.053714\n",
            "Train Epoch: 4 [16000/60032 (27%)]\tLoss: 0.206703\n",
            "Train Epoch: 4 [16640/60032 (28%)]\tLoss: 0.110025\n",
            "Train Epoch: 4 [17280/60032 (29%)]\tLoss: 0.031182\n",
            "Train Epoch: 4 [17920/60032 (30%)]\tLoss: 0.075758\n",
            "Train Epoch: 4 [18560/60032 (31%)]\tLoss: 0.169777\n",
            "Train Epoch: 4 [19200/60032 (32%)]\tLoss: 0.048577\n",
            "Train Epoch: 4 [19840/60032 (33%)]\tLoss: 0.040666\n",
            "Train Epoch: 4 [20480/60032 (34%)]\tLoss: 0.013506\n",
            "Train Epoch: 4 [21120/60032 (35%)]\tLoss: 0.059008\n",
            "Train Epoch: 4 [21760/60032 (36%)]\tLoss: 0.040612\n",
            "Train Epoch: 4 [22400/60032 (37%)]\tLoss: 0.028642\n",
            "Train Epoch: 4 [23040/60032 (38%)]\tLoss: 0.022643\n",
            "Train Epoch: 4 [23680/60032 (39%)]\tLoss: 0.015776\n",
            "Train Epoch: 4 [24320/60032 (41%)]\tLoss: 0.026703\n",
            "Train Epoch: 4 [24960/60032 (42%)]\tLoss: 0.028001\n",
            "Train Epoch: 4 [25600/60032 (43%)]\tLoss: 0.010697\n",
            "Train Epoch: 4 [26240/60032 (44%)]\tLoss: 0.104100\n",
            "Train Epoch: 4 [26880/60032 (45%)]\tLoss: 0.064341\n",
            "Train Epoch: 4 [27520/60032 (46%)]\tLoss: 0.117843\n",
            "Train Epoch: 4 [28160/60032 (47%)]\tLoss: 0.050684\n",
            "Train Epoch: 4 [28800/60032 (48%)]\tLoss: 0.041753\n",
            "Train Epoch: 4 [29440/60032 (49%)]\tLoss: 0.108582\n",
            "Train Epoch: 4 [30080/60032 (50%)]\tLoss: 0.147375\n",
            "Train Epoch: 4 [30720/60032 (51%)]\tLoss: 0.066452\n",
            "Train Epoch: 4 [31360/60032 (52%)]\tLoss: 0.067046\n",
            "Train Epoch: 4 [32000/60032 (53%)]\tLoss: 0.043740\n",
            "Train Epoch: 4 [32640/60032 (54%)]\tLoss: 0.101191\n",
            "Train Epoch: 4 [33280/60032 (55%)]\tLoss: 0.077127\n",
            "Train Epoch: 4 [33920/60032 (57%)]\tLoss: 0.289105\n",
            "Train Epoch: 4 [34560/60032 (58%)]\tLoss: 0.029631\n",
            "Train Epoch: 4 [35200/60032 (59%)]\tLoss: 0.095237\n",
            "Train Epoch: 4 [35840/60032 (60%)]\tLoss: 0.077114\n",
            "Train Epoch: 4 [36480/60032 (61%)]\tLoss: 0.015160\n",
            "Train Epoch: 4 [37120/60032 (62%)]\tLoss: 0.059942\n",
            "Train Epoch: 4 [37760/60032 (63%)]\tLoss: 0.021309\n",
            "Train Epoch: 4 [38400/60032 (64%)]\tLoss: 0.018721\n",
            "Train Epoch: 4 [39040/60032 (65%)]\tLoss: 0.115997\n",
            "Train Epoch: 4 [39680/60032 (66%)]\tLoss: 0.080439\n",
            "Train Epoch: 4 [40320/60032 (67%)]\tLoss: 0.021452\n",
            "Train Epoch: 4 [40960/60032 (68%)]\tLoss: 0.096415\n",
            "Train Epoch: 4 [41600/60032 (69%)]\tLoss: 0.114575\n",
            "Train Epoch: 4 [42240/60032 (70%)]\tLoss: 0.048557\n",
            "Train Epoch: 4 [42880/60032 (71%)]\tLoss: 0.062080\n",
            "Train Epoch: 4 [43520/60032 (72%)]\tLoss: 0.078118\n",
            "Train Epoch: 4 [44160/60032 (74%)]\tLoss: 0.018452\n",
            "Train Epoch: 4 [44800/60032 (75%)]\tLoss: 0.087822\n",
            "Train Epoch: 4 [45440/60032 (76%)]\tLoss: 0.085750\n",
            "Train Epoch: 4 [46080/60032 (77%)]\tLoss: 0.042858\n",
            "Train Epoch: 4 [46720/60032 (78%)]\tLoss: 0.020406\n",
            "Train Epoch: 4 [47360/60032 (79%)]\tLoss: 0.088581\n",
            "Train Epoch: 4 [48000/60032 (80%)]\tLoss: 0.042961\n",
            "Train Epoch: 4 [48640/60032 (81%)]\tLoss: 0.133279\n",
            "Train Epoch: 4 [49280/60032 (82%)]\tLoss: 0.053891\n",
            "Train Epoch: 4 [49920/60032 (83%)]\tLoss: 0.036043\n",
            "Train Epoch: 4 [50560/60032 (84%)]\tLoss: 0.059074\n",
            "Train Epoch: 4 [51200/60032 (85%)]\tLoss: 0.079376\n",
            "Train Epoch: 4 [51840/60032 (86%)]\tLoss: 0.085440\n",
            "Train Epoch: 4 [52480/60032 (87%)]\tLoss: 0.077910\n",
            "Train Epoch: 4 [53120/60032 (88%)]\tLoss: 0.057747\n",
            "Train Epoch: 4 [53760/60032 (90%)]\tLoss: 0.069264\n",
            "Train Epoch: 4 [54400/60032 (91%)]\tLoss: 0.039962\n",
            "Train Epoch: 4 [55040/60032 (92%)]\tLoss: 0.160253\n",
            "Train Epoch: 4 [55680/60032 (93%)]\tLoss: 0.025453\n",
            "Train Epoch: 4 [56320/60032 (94%)]\tLoss: 0.066381\n",
            "Train Epoch: 4 [56960/60032 (95%)]\tLoss: 0.014517\n",
            "Train Epoch: 4 [57600/60032 (96%)]\tLoss: 0.141360\n",
            "Train Epoch: 4 [58240/60032 (97%)]\tLoss: 0.047100\n",
            "Train Epoch: 4 [58880/60032 (98%)]\tLoss: 0.078018\n",
            "Train Epoch: 4 [59520/60032 (99%)]\tLoss: 0.066236\n",
            "\n",
            "Test set: Average loss: 0.0540, Accuracy: 9829/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60032 (0%)]\tLoss: 0.081924\n",
            "Train Epoch: 5 [640/60032 (1%)]\tLoss: 0.015374\n",
            "Train Epoch: 5 [1280/60032 (2%)]\tLoss: 0.097924\n",
            "Train Epoch: 5 [1920/60032 (3%)]\tLoss: 0.039348\n",
            "Train Epoch: 5 [2560/60032 (4%)]\tLoss: 0.025723\n",
            "Train Epoch: 5 [3200/60032 (5%)]\tLoss: 0.125181\n",
            "Train Epoch: 5 [3840/60032 (6%)]\tLoss: 0.068640\n",
            "Train Epoch: 5 [4480/60032 (7%)]\tLoss: 0.049471\n",
            "Train Epoch: 5 [5120/60032 (9%)]\tLoss: 0.059642\n",
            "Train Epoch: 5 [5760/60032 (10%)]\tLoss: 0.163147\n",
            "Train Epoch: 5 [6400/60032 (11%)]\tLoss: 0.042618\n",
            "Train Epoch: 5 [7040/60032 (12%)]\tLoss: 0.026150\n",
            "Train Epoch: 5 [7680/60032 (13%)]\tLoss: 0.028368\n",
            "Train Epoch: 5 [8320/60032 (14%)]\tLoss: 0.022722\n",
            "Train Epoch: 5 [8960/60032 (15%)]\tLoss: 0.021927\n",
            "Train Epoch: 5 [9600/60032 (16%)]\tLoss: 0.019555\n",
            "Train Epoch: 5 [10240/60032 (17%)]\tLoss: 0.144159\n",
            "Train Epoch: 5 [10880/60032 (18%)]\tLoss: 0.065004\n",
            "Train Epoch: 5 [11520/60032 (19%)]\tLoss: 0.044185\n",
            "Train Epoch: 5 [12160/60032 (20%)]\tLoss: 0.070028\n",
            "Train Epoch: 5 [12800/60032 (21%)]\tLoss: 0.009355\n",
            "Train Epoch: 5 [13440/60032 (22%)]\tLoss: 0.013997\n",
            "Train Epoch: 5 [14080/60032 (23%)]\tLoss: 0.016394\n",
            "Train Epoch: 5 [14720/60032 (25%)]\tLoss: 0.037026\n",
            "Train Epoch: 5 [15360/60032 (26%)]\tLoss: 0.042268\n",
            "Train Epoch: 5 [16000/60032 (27%)]\tLoss: 0.104159\n",
            "Train Epoch: 5 [16640/60032 (28%)]\tLoss: 0.052741\n",
            "Train Epoch: 5 [17280/60032 (29%)]\tLoss: 0.110540\n",
            "Train Epoch: 5 [17920/60032 (30%)]\tLoss: 0.027530\n",
            "Train Epoch: 5 [18560/60032 (31%)]\tLoss: 0.030219\n",
            "Train Epoch: 5 [19200/60032 (32%)]\tLoss: 0.048871\n",
            "Train Epoch: 5 [19840/60032 (33%)]\tLoss: 0.034563\n",
            "Train Epoch: 5 [20480/60032 (34%)]\tLoss: 0.024592\n",
            "Train Epoch: 5 [21120/60032 (35%)]\tLoss: 0.016225\n",
            "Train Epoch: 5 [21760/60032 (36%)]\tLoss: 0.026098\n",
            "Train Epoch: 5 [22400/60032 (37%)]\tLoss: 0.101536\n",
            "Train Epoch: 5 [23040/60032 (38%)]\tLoss: 0.110543\n",
            "Train Epoch: 5 [23680/60032 (39%)]\tLoss: 0.036656\n",
            "Train Epoch: 5 [24320/60032 (41%)]\tLoss: 0.047768\n",
            "Train Epoch: 5 [24960/60032 (42%)]\tLoss: 0.129758\n",
            "Train Epoch: 5 [25600/60032 (43%)]\tLoss: 0.041509\n",
            "Train Epoch: 5 [26240/60032 (44%)]\tLoss: 0.044444\n",
            "Train Epoch: 5 [26880/60032 (45%)]\tLoss: 0.081284\n",
            "Train Epoch: 5 [27520/60032 (46%)]\tLoss: 0.071021\n",
            "Train Epoch: 5 [28160/60032 (47%)]\tLoss: 0.112383\n",
            "Train Epoch: 5 [28800/60032 (48%)]\tLoss: 0.049279\n",
            "Train Epoch: 5 [29440/60032 (49%)]\tLoss: 0.069617\n",
            "Train Epoch: 5 [30080/60032 (50%)]\tLoss: 0.135890\n",
            "Train Epoch: 5 [30720/60032 (51%)]\tLoss: 0.031993\n",
            "Train Epoch: 5 [31360/60032 (52%)]\tLoss: 0.016695\n",
            "Train Epoch: 5 [32000/60032 (53%)]\tLoss: 0.072022\n",
            "Train Epoch: 5 [32640/60032 (54%)]\tLoss: 0.045700\n",
            "Train Epoch: 5 [33280/60032 (55%)]\tLoss: 0.025777\n",
            "Train Epoch: 5 [33920/60032 (57%)]\tLoss: 0.071615\n",
            "Train Epoch: 5 [34560/60032 (58%)]\tLoss: 0.071562\n",
            "Train Epoch: 5 [35200/60032 (59%)]\tLoss: 0.010584\n",
            "Train Epoch: 5 [35840/60032 (60%)]\tLoss: 0.129944\n",
            "Train Epoch: 5 [36480/60032 (61%)]\tLoss: 0.110042\n",
            "Train Epoch: 5 [37120/60032 (62%)]\tLoss: 0.027074\n",
            "Train Epoch: 5 [37760/60032 (63%)]\tLoss: 0.077765\n",
            "Train Epoch: 5 [38400/60032 (64%)]\tLoss: 0.051385\n",
            "Train Epoch: 5 [39040/60032 (65%)]\tLoss: 0.035176\n",
            "Train Epoch: 5 [39680/60032 (66%)]\tLoss: 0.031682\n",
            "Train Epoch: 5 [40320/60032 (67%)]\tLoss: 0.020768\n",
            "Train Epoch: 5 [40960/60032 (68%)]\tLoss: 0.048615\n",
            "Train Epoch: 5 [41600/60032 (69%)]\tLoss: 0.075645\n",
            "Train Epoch: 5 [42240/60032 (70%)]\tLoss: 0.007804\n",
            "Train Epoch: 5 [42880/60032 (71%)]\tLoss: 0.012269\n",
            "Train Epoch: 5 [43520/60032 (72%)]\tLoss: 0.031712\n",
            "Train Epoch: 5 [44160/60032 (74%)]\tLoss: 0.046971\n",
            "Train Epoch: 5 [44800/60032 (75%)]\tLoss: 0.030836\n",
            "Train Epoch: 5 [45440/60032 (76%)]\tLoss: 0.143388\n",
            "Train Epoch: 5 [46080/60032 (77%)]\tLoss: 0.032118\n",
            "Train Epoch: 5 [46720/60032 (78%)]\tLoss: 0.109610\n",
            "Train Epoch: 5 [47360/60032 (79%)]\tLoss: 0.115502\n",
            "Train Epoch: 5 [48000/60032 (80%)]\tLoss: 0.032392\n",
            "Train Epoch: 5 [48640/60032 (81%)]\tLoss: 0.061364\n",
            "Train Epoch: 5 [49280/60032 (82%)]\tLoss: 0.008994\n",
            "Train Epoch: 5 [49920/60032 (83%)]\tLoss: 0.036582\n",
            "Train Epoch: 5 [50560/60032 (84%)]\tLoss: 0.022158\n",
            "Train Epoch: 5 [51200/60032 (85%)]\tLoss: 0.027238\n",
            "Train Epoch: 5 [51840/60032 (86%)]\tLoss: 0.014065\n",
            "Train Epoch: 5 [52480/60032 (87%)]\tLoss: 0.099267\n",
            "Train Epoch: 5 [53120/60032 (88%)]\tLoss: 0.060517\n",
            "Train Epoch: 5 [53760/60032 (90%)]\tLoss: 0.082076\n",
            "Train Epoch: 5 [54400/60032 (91%)]\tLoss: 0.063767\n",
            "Train Epoch: 5 [55040/60032 (92%)]\tLoss: 0.028237\n",
            "Train Epoch: 5 [55680/60032 (93%)]\tLoss: 0.061756\n",
            "Train Epoch: 5 [56320/60032 (94%)]\tLoss: 0.075784\n",
            "Train Epoch: 5 [56960/60032 (95%)]\tLoss: 0.054621\n",
            "Train Epoch: 5 [57600/60032 (96%)]\tLoss: 0.162606\n",
            "Train Epoch: 5 [58240/60032 (97%)]\tLoss: 0.049569\n",
            "Train Epoch: 5 [58880/60032 (98%)]\tLoss: 0.048582\n",
            "Train Epoch: 5 [59520/60032 (99%)]\tLoss: 0.066632\n",
            "\n",
            "Test set: Average loss: 0.0511, Accuracy: 9832/10000 (98%)\n",
            "\n",
            "Train Epoch: 6 [0/60032 (0%)]\tLoss: 0.018664\n",
            "Train Epoch: 6 [640/60032 (1%)]\tLoss: 0.014976\n",
            "Train Epoch: 6 [1280/60032 (2%)]\tLoss: 0.044882\n",
            "Train Epoch: 6 [1920/60032 (3%)]\tLoss: 0.004069\n",
            "Train Epoch: 6 [2560/60032 (4%)]\tLoss: 0.028087\n",
            "Train Epoch: 6 [3200/60032 (5%)]\tLoss: 0.079024\n",
            "Train Epoch: 6 [3840/60032 (6%)]\tLoss: 0.023726\n",
            "Train Epoch: 6 [4480/60032 (7%)]\tLoss: 0.031499\n",
            "Train Epoch: 6 [5120/60032 (9%)]\tLoss: 0.046208\n",
            "Train Epoch: 6 [5760/60032 (10%)]\tLoss: 0.102953\n",
            "Train Epoch: 6 [6400/60032 (11%)]\tLoss: 0.185928\n",
            "Train Epoch: 6 [7040/60032 (12%)]\tLoss: 0.139114\n",
            "Train Epoch: 6 [7680/60032 (13%)]\tLoss: 0.027257\n",
            "Train Epoch: 6 [8320/60032 (14%)]\tLoss: 0.018990\n",
            "Train Epoch: 6 [8960/60032 (15%)]\tLoss: 0.042606\n",
            "Train Epoch: 6 [9600/60032 (16%)]\tLoss: 0.143414\n",
            "Train Epoch: 6 [10240/60032 (17%)]\tLoss: 0.016445\n",
            "Train Epoch: 6 [10880/60032 (18%)]\tLoss: 0.010576\n",
            "Train Epoch: 6 [11520/60032 (19%)]\tLoss: 0.040294\n",
            "Train Epoch: 6 [12160/60032 (20%)]\tLoss: 0.052590\n",
            "Train Epoch: 6 [12800/60032 (21%)]\tLoss: 0.004996\n",
            "Train Epoch: 6 [13440/60032 (22%)]\tLoss: 0.038603\n",
            "Train Epoch: 6 [14080/60032 (23%)]\tLoss: 0.012254\n",
            "Train Epoch: 6 [14720/60032 (25%)]\tLoss: 0.077737\n",
            "Train Epoch: 6 [15360/60032 (26%)]\tLoss: 0.023783\n",
            "Train Epoch: 6 [16000/60032 (27%)]\tLoss: 0.013339\n",
            "Train Epoch: 6 [16640/60032 (28%)]\tLoss: 0.049354\n",
            "Train Epoch: 6 [17280/60032 (29%)]\tLoss: 0.022739\n",
            "Train Epoch: 6 [17920/60032 (30%)]\tLoss: 0.039500\n",
            "Train Epoch: 6 [18560/60032 (31%)]\tLoss: 0.085651\n",
            "Train Epoch: 6 [19200/60032 (32%)]\tLoss: 0.114724\n",
            "Train Epoch: 6 [19840/60032 (33%)]\tLoss: 0.028331\n",
            "Train Epoch: 6 [20480/60032 (34%)]\tLoss: 0.022225\n",
            "Train Epoch: 6 [21120/60032 (35%)]\tLoss: 0.019392\n",
            "Train Epoch: 6 [21760/60032 (36%)]\tLoss: 0.083442\n",
            "Train Epoch: 6 [22400/60032 (37%)]\tLoss: 0.186402\n",
            "Train Epoch: 6 [23040/60032 (38%)]\tLoss: 0.066265\n",
            "Train Epoch: 6 [23680/60032 (39%)]\tLoss: 0.019964\n",
            "Train Epoch: 6 [24320/60032 (41%)]\tLoss: 0.095168\n",
            "Train Epoch: 6 [24960/60032 (42%)]\tLoss: 0.064652\n",
            "Train Epoch: 6 [25600/60032 (43%)]\tLoss: 0.044061\n",
            "Train Epoch: 6 [26240/60032 (44%)]\tLoss: 0.035906\n",
            "Train Epoch: 6 [26880/60032 (45%)]\tLoss: 0.021164\n",
            "Train Epoch: 6 [27520/60032 (46%)]\tLoss: 0.014787\n",
            "Train Epoch: 6 [28160/60032 (47%)]\tLoss: 0.021802\n",
            "Train Epoch: 6 [28800/60032 (48%)]\tLoss: 0.010524\n",
            "Train Epoch: 6 [29440/60032 (49%)]\tLoss: 0.022302\n",
            "Train Epoch: 6 [30080/60032 (50%)]\tLoss: 0.027761\n",
            "Train Epoch: 6 [30720/60032 (51%)]\tLoss: 0.058236\n",
            "Train Epoch: 6 [31360/60032 (52%)]\tLoss: 0.014287\n",
            "Train Epoch: 6 [32000/60032 (53%)]\tLoss: 0.095380\n",
            "Train Epoch: 6 [32640/60032 (54%)]\tLoss: 0.035867\n",
            "Train Epoch: 6 [33280/60032 (55%)]\tLoss: 0.052001\n",
            "Train Epoch: 6 [33920/60032 (57%)]\tLoss: 0.059063\n",
            "Train Epoch: 6 [34560/60032 (58%)]\tLoss: 0.034194\n",
            "Train Epoch: 6 [35200/60032 (59%)]\tLoss: 0.093880\n",
            "Train Epoch: 6 [35840/60032 (60%)]\tLoss: 0.043308\n",
            "Train Epoch: 6 [36480/60032 (61%)]\tLoss: 0.006953\n",
            "Train Epoch: 6 [37120/60032 (62%)]\tLoss: 0.108793\n",
            "Train Epoch: 6 [37760/60032 (63%)]\tLoss: 0.083134\n",
            "Train Epoch: 6 [38400/60032 (64%)]\tLoss: 0.032603\n",
            "Train Epoch: 6 [39040/60032 (65%)]\tLoss: 0.118709\n",
            "Train Epoch: 6 [39680/60032 (66%)]\tLoss: 0.031529\n",
            "Train Epoch: 6 [40320/60032 (67%)]\tLoss: 0.069614\n",
            "Train Epoch: 6 [40960/60032 (68%)]\tLoss: 0.088948\n",
            "Train Epoch: 6 [41600/60032 (69%)]\tLoss: 0.017720\n",
            "Train Epoch: 6 [42240/60032 (70%)]\tLoss: 0.034691\n",
            "Train Epoch: 6 [42880/60032 (71%)]\tLoss: 0.008583\n",
            "Train Epoch: 6 [43520/60032 (72%)]\tLoss: 0.063493\n",
            "Train Epoch: 6 [44160/60032 (74%)]\tLoss: 0.020183\n",
            "Train Epoch: 6 [44800/60032 (75%)]\tLoss: 0.013531\n",
            "Train Epoch: 6 [45440/60032 (76%)]\tLoss: 0.008411\n",
            "Train Epoch: 6 [46080/60032 (77%)]\tLoss: 0.019316\n",
            "Train Epoch: 6 [46720/60032 (78%)]\tLoss: 0.040148\n",
            "Train Epoch: 6 [47360/60032 (79%)]\tLoss: 0.092643\n",
            "Train Epoch: 6 [48000/60032 (80%)]\tLoss: 0.089998\n",
            "Train Epoch: 6 [48640/60032 (81%)]\tLoss: 0.124387\n",
            "Train Epoch: 6 [49280/60032 (82%)]\tLoss: 0.028365\n",
            "Train Epoch: 6 [49920/60032 (83%)]\tLoss: 0.061354\n",
            "Train Epoch: 6 [50560/60032 (84%)]\tLoss: 0.028420\n",
            "Train Epoch: 6 [51200/60032 (85%)]\tLoss: 0.032534\n",
            "Train Epoch: 6 [51840/60032 (86%)]\tLoss: 0.049841\n",
            "Train Epoch: 6 [52480/60032 (87%)]\tLoss: 0.108181\n",
            "Train Epoch: 6 [53120/60032 (88%)]\tLoss: 0.092247\n",
            "Train Epoch: 6 [53760/60032 (90%)]\tLoss: 0.004867\n",
            "Train Epoch: 6 [54400/60032 (91%)]\tLoss: 0.046290\n",
            "Train Epoch: 6 [55040/60032 (92%)]\tLoss: 0.082611\n",
            "Train Epoch: 6 [55680/60032 (93%)]\tLoss: 0.034637\n",
            "Train Epoch: 6 [56320/60032 (94%)]\tLoss: 0.121497\n",
            "Train Epoch: 6 [56960/60032 (95%)]\tLoss: 0.004988\n",
            "Train Epoch: 6 [57600/60032 (96%)]\tLoss: 0.046081\n",
            "Train Epoch: 6 [58240/60032 (97%)]\tLoss: 0.046792\n",
            "Train Epoch: 6 [58880/60032 (98%)]\tLoss: 0.267589\n",
            "Train Epoch: 6 [59520/60032 (99%)]\tLoss: 0.020084\n",
            "\n",
            "Test set: Average loss: 0.0468, Accuracy: 9856/10000 (99%)\n",
            "\n",
            "Train Epoch: 7 [0/60032 (0%)]\tLoss: 0.056901\n",
            "Train Epoch: 7 [640/60032 (1%)]\tLoss: 0.006741\n",
            "Train Epoch: 7 [1280/60032 (2%)]\tLoss: 0.024896\n",
            "Train Epoch: 7 [1920/60032 (3%)]\tLoss: 0.031458\n",
            "Train Epoch: 7 [2560/60032 (4%)]\tLoss: 0.034625\n",
            "Train Epoch: 7 [3200/60032 (5%)]\tLoss: 0.025065\n",
            "Train Epoch: 7 [3840/60032 (6%)]\tLoss: 0.070708\n",
            "Train Epoch: 7 [4480/60032 (7%)]\tLoss: 0.031162\n",
            "Train Epoch: 7 [5120/60032 (9%)]\tLoss: 0.020249\n",
            "Train Epoch: 7 [5760/60032 (10%)]\tLoss: 0.016971\n",
            "Train Epoch: 7 [6400/60032 (11%)]\tLoss: 0.015445\n",
            "Train Epoch: 7 [7040/60032 (12%)]\tLoss: 0.017882\n",
            "Train Epoch: 7 [7680/60032 (13%)]\tLoss: 0.009787\n",
            "Train Epoch: 7 [8320/60032 (14%)]\tLoss: 0.061559\n",
            "Train Epoch: 7 [8960/60032 (15%)]\tLoss: 0.008103\n",
            "Train Epoch: 7 [9600/60032 (16%)]\tLoss: 0.038684\n",
            "Train Epoch: 7 [10240/60032 (17%)]\tLoss: 0.039280\n",
            "Train Epoch: 7 [10880/60032 (18%)]\tLoss: 0.042986\n",
            "Train Epoch: 7 [11520/60032 (19%)]\tLoss: 0.014293\n",
            "Train Epoch: 7 [12160/60032 (20%)]\tLoss: 0.127521\n",
            "Train Epoch: 7 [12800/60032 (21%)]\tLoss: 0.076725\n",
            "Train Epoch: 7 [13440/60032 (22%)]\tLoss: 0.075193\n",
            "Train Epoch: 7 [14080/60032 (23%)]\tLoss: 0.063399\n",
            "Train Epoch: 7 [14720/60032 (25%)]\tLoss: 0.004371\n",
            "Train Epoch: 7 [15360/60032 (26%)]\tLoss: 0.004286\n",
            "Train Epoch: 7 [16000/60032 (27%)]\tLoss: 0.050153\n",
            "Train Epoch: 7 [16640/60032 (28%)]\tLoss: 0.032171\n",
            "Train Epoch: 7 [17280/60032 (29%)]\tLoss: 0.026259\n",
            "Train Epoch: 7 [17920/60032 (30%)]\tLoss: 0.033870\n",
            "Train Epoch: 7 [18560/60032 (31%)]\tLoss: 0.059887\n",
            "Train Epoch: 7 [19200/60032 (32%)]\tLoss: 0.026600\n",
            "Train Epoch: 7 [19840/60032 (33%)]\tLoss: 0.144386\n",
            "Train Epoch: 7 [20480/60032 (34%)]\tLoss: 0.030179\n",
            "Train Epoch: 7 [21120/60032 (35%)]\tLoss: 0.015179\n",
            "Train Epoch: 7 [21760/60032 (36%)]\tLoss: 0.125560\n",
            "Train Epoch: 7 [22400/60032 (37%)]\tLoss: 0.037840\n",
            "Train Epoch: 7 [23040/60032 (38%)]\tLoss: 0.090658\n",
            "Train Epoch: 7 [23680/60032 (39%)]\tLoss: 0.081400\n",
            "Train Epoch: 7 [24320/60032 (41%)]\tLoss: 0.050949\n",
            "Train Epoch: 7 [24960/60032 (42%)]\tLoss: 0.025051\n",
            "Train Epoch: 7 [25600/60032 (43%)]\tLoss: 0.009814\n",
            "Train Epoch: 7 [26240/60032 (44%)]\tLoss: 0.142608\n",
            "Train Epoch: 7 [26880/60032 (45%)]\tLoss: 0.015572\n",
            "Train Epoch: 7 [27520/60032 (46%)]\tLoss: 0.030956\n",
            "Train Epoch: 7 [28160/60032 (47%)]\tLoss: 0.046741\n",
            "Train Epoch: 7 [28800/60032 (48%)]\tLoss: 0.091249\n",
            "Train Epoch: 7 [29440/60032 (49%)]\tLoss: 0.073562\n",
            "Train Epoch: 7 [30080/60032 (50%)]\tLoss: 0.037572\n",
            "Train Epoch: 7 [30720/60032 (51%)]\tLoss: 0.054722\n",
            "Train Epoch: 7 [31360/60032 (52%)]\tLoss: 0.086349\n",
            "Train Epoch: 7 [32000/60032 (53%)]\tLoss: 0.060402\n",
            "Train Epoch: 7 [32640/60032 (54%)]\tLoss: 0.057102\n",
            "Train Epoch: 7 [33280/60032 (55%)]\tLoss: 0.040416\n",
            "Train Epoch: 7 [33920/60032 (57%)]\tLoss: 0.026594\n",
            "Train Epoch: 7 [34560/60032 (58%)]\tLoss: 0.005121\n",
            "Train Epoch: 7 [35200/60032 (59%)]\tLoss: 0.022149\n",
            "Train Epoch: 7 [35840/60032 (60%)]\tLoss: 0.028234\n",
            "Train Epoch: 7 [36480/60032 (61%)]\tLoss: 0.016759\n",
            "Train Epoch: 7 [37120/60032 (62%)]\tLoss: 0.062972\n",
            "Train Epoch: 7 [37760/60032 (63%)]\tLoss: 0.066992\n",
            "Train Epoch: 7 [38400/60032 (64%)]\tLoss: 0.004885\n",
            "Train Epoch: 7 [39040/60032 (65%)]\tLoss: 0.076874\n",
            "Train Epoch: 7 [39680/60032 (66%)]\tLoss: 0.014290\n",
            "Train Epoch: 7 [40320/60032 (67%)]\tLoss: 0.084088\n",
            "Train Epoch: 7 [40960/60032 (68%)]\tLoss: 0.016347\n",
            "Train Epoch: 7 [41600/60032 (69%)]\tLoss: 0.018124\n",
            "Train Epoch: 7 [42240/60032 (70%)]\tLoss: 0.010727\n",
            "Train Epoch: 7 [42880/60032 (71%)]\tLoss: 0.045999\n",
            "Train Epoch: 7 [43520/60032 (72%)]\tLoss: 0.045311\n",
            "Train Epoch: 7 [44160/60032 (74%)]\tLoss: 0.063721\n",
            "Train Epoch: 7 [44800/60032 (75%)]\tLoss: 0.100968\n",
            "Train Epoch: 7 [45440/60032 (76%)]\tLoss: 0.031618\n",
            "Train Epoch: 7 [46080/60032 (77%)]\tLoss: 0.107997\n",
            "Train Epoch: 7 [46720/60032 (78%)]\tLoss: 0.103447\n",
            "Train Epoch: 7 [47360/60032 (79%)]\tLoss: 0.011754\n",
            "Train Epoch: 7 [48000/60032 (80%)]\tLoss: 0.097303\n",
            "Train Epoch: 7 [48640/60032 (81%)]\tLoss: 0.059531\n",
            "Train Epoch: 7 [49280/60032 (82%)]\tLoss: 0.053060\n",
            "Train Epoch: 7 [49920/60032 (83%)]\tLoss: 0.021428\n",
            "Train Epoch: 7 [50560/60032 (84%)]\tLoss: 0.078765\n",
            "Train Epoch: 7 [51200/60032 (85%)]\tLoss: 0.050765\n",
            "Train Epoch: 7 [51840/60032 (86%)]\tLoss: 0.023104\n",
            "Train Epoch: 7 [52480/60032 (87%)]\tLoss: 0.029670\n",
            "Train Epoch: 7 [53120/60032 (88%)]\tLoss: 0.008273\n",
            "Train Epoch: 7 [53760/60032 (90%)]\tLoss: 0.015880\n",
            "Train Epoch: 7 [54400/60032 (91%)]\tLoss: 0.010420\n",
            "Train Epoch: 7 [55040/60032 (92%)]\tLoss: 0.056431\n",
            "Train Epoch: 7 [55680/60032 (93%)]\tLoss: 0.067697\n",
            "Train Epoch: 7 [56320/60032 (94%)]\tLoss: 0.025539\n",
            "Train Epoch: 7 [56960/60032 (95%)]\tLoss: 0.017635\n",
            "Train Epoch: 7 [57600/60032 (96%)]\tLoss: 0.111849\n",
            "Train Epoch: 7 [58240/60032 (97%)]\tLoss: 0.033287\n",
            "Train Epoch: 7 [58880/60032 (98%)]\tLoss: 0.052817\n",
            "Train Epoch: 7 [59520/60032 (99%)]\tLoss: 0.052814\n",
            "\n",
            "Test set: Average loss: 0.0398, Accuracy: 9872/10000 (99%)\n",
            "\n",
            "Train Epoch: 8 [0/60032 (0%)]\tLoss: 0.018472\n",
            "Train Epoch: 8 [640/60032 (1%)]\tLoss: 0.019025\n",
            "Train Epoch: 8 [1280/60032 (2%)]\tLoss: 0.162303\n",
            "Train Epoch: 8 [1920/60032 (3%)]\tLoss: 0.103011\n",
            "Train Epoch: 8 [2560/60032 (4%)]\tLoss: 0.142573\n",
            "Train Epoch: 8 [3200/60032 (5%)]\tLoss: 0.003178\n",
            "Train Epoch: 8 [3840/60032 (6%)]\tLoss: 0.032976\n",
            "Train Epoch: 8 [4480/60032 (7%)]\tLoss: 0.131732\n",
            "Train Epoch: 8 [5120/60032 (9%)]\tLoss: 0.066634\n",
            "Train Epoch: 8 [5760/60032 (10%)]\tLoss: 0.018182\n",
            "Train Epoch: 8 [6400/60032 (11%)]\tLoss: 0.004475\n",
            "Train Epoch: 8 [7040/60032 (12%)]\tLoss: 0.013032\n",
            "Train Epoch: 8 [7680/60032 (13%)]\tLoss: 0.085505\n",
            "Train Epoch: 8 [8320/60032 (14%)]\tLoss: 0.018616\n",
            "Train Epoch: 8 [8960/60032 (15%)]\tLoss: 0.013674\n",
            "Train Epoch: 8 [9600/60032 (16%)]\tLoss: 0.041342\n",
            "Train Epoch: 8 [10240/60032 (17%)]\tLoss: 0.037214\n",
            "Train Epoch: 8 [10880/60032 (18%)]\tLoss: 0.030504\n",
            "Train Epoch: 8 [11520/60032 (19%)]\tLoss: 0.030672\n",
            "Train Epoch: 8 [12160/60032 (20%)]\tLoss: 0.049705\n",
            "Train Epoch: 8 [12800/60032 (21%)]\tLoss: 0.019311\n",
            "Train Epoch: 8 [13440/60032 (22%)]\tLoss: 0.036724\n",
            "Train Epoch: 8 [14080/60032 (23%)]\tLoss: 0.019182\n",
            "Train Epoch: 8 [14720/60032 (25%)]\tLoss: 0.005742\n",
            "Train Epoch: 8 [15360/60032 (26%)]\tLoss: 0.027481\n",
            "Train Epoch: 8 [16000/60032 (27%)]\tLoss: 0.025104\n",
            "Train Epoch: 8 [16640/60032 (28%)]\tLoss: 0.010546\n",
            "Train Epoch: 8 [17280/60032 (29%)]\tLoss: 0.019328\n",
            "Train Epoch: 8 [17920/60032 (30%)]\tLoss: 0.040923\n",
            "Train Epoch: 8 [18560/60032 (31%)]\tLoss: 0.001908\n",
            "Train Epoch: 8 [19200/60032 (32%)]\tLoss: 0.034013\n",
            "Train Epoch: 8 [19840/60032 (33%)]\tLoss: 0.006022\n",
            "Train Epoch: 8 [20480/60032 (34%)]\tLoss: 0.035456\n",
            "Train Epoch: 8 [21120/60032 (35%)]\tLoss: 0.009294\n",
            "Train Epoch: 8 [21760/60032 (36%)]\tLoss: 0.012171\n",
            "Train Epoch: 8 [22400/60032 (37%)]\tLoss: 0.092695\n",
            "Train Epoch: 8 [23040/60032 (38%)]\tLoss: 0.043805\n",
            "Train Epoch: 8 [23680/60032 (39%)]\tLoss: 0.054267\n",
            "Train Epoch: 8 [24320/60032 (41%)]\tLoss: 0.018463\n",
            "Train Epoch: 8 [24960/60032 (42%)]\tLoss: 0.057252\n",
            "Train Epoch: 8 [25600/60032 (43%)]\tLoss: 0.032950\n",
            "Train Epoch: 8 [26240/60032 (44%)]\tLoss: 0.003624\n",
            "Train Epoch: 8 [26880/60032 (45%)]\tLoss: 0.007029\n",
            "Train Epoch: 8 [27520/60032 (46%)]\tLoss: 0.007066\n",
            "Train Epoch: 8 [28160/60032 (47%)]\tLoss: 0.055477\n",
            "Train Epoch: 8 [28800/60032 (48%)]\tLoss: 0.021833\n",
            "Train Epoch: 8 [29440/60032 (49%)]\tLoss: 0.015037\n",
            "Train Epoch: 8 [30080/60032 (50%)]\tLoss: 0.046263\n",
            "Train Epoch: 8 [30720/60032 (51%)]\tLoss: 0.013095\n",
            "Train Epoch: 8 [31360/60032 (52%)]\tLoss: 0.029364\n",
            "Train Epoch: 8 [32000/60032 (53%)]\tLoss: 0.013990\n",
            "Train Epoch: 8 [32640/60032 (54%)]\tLoss: 0.049522\n",
            "Train Epoch: 8 [33280/60032 (55%)]\tLoss: 0.006070\n",
            "Train Epoch: 8 [33920/60032 (57%)]\tLoss: 0.067379\n",
            "Train Epoch: 8 [34560/60032 (58%)]\tLoss: 0.051399\n",
            "Train Epoch: 8 [35200/60032 (59%)]\tLoss: 0.028402\n",
            "Train Epoch: 8 [35840/60032 (60%)]\tLoss: 0.026912\n",
            "Train Epoch: 8 [36480/60032 (61%)]\tLoss: 0.014464\n",
            "Train Epoch: 8 [37120/60032 (62%)]\tLoss: 0.035034\n",
            "Train Epoch: 8 [37760/60032 (63%)]\tLoss: 0.127952\n",
            "Train Epoch: 8 [38400/60032 (64%)]\tLoss: 0.084664\n",
            "Train Epoch: 8 [39040/60032 (65%)]\tLoss: 0.009118\n",
            "Train Epoch: 8 [39680/60032 (66%)]\tLoss: 0.060572\n",
            "Train Epoch: 8 [40320/60032 (67%)]\tLoss: 0.063022\n",
            "Train Epoch: 8 [40960/60032 (68%)]\tLoss: 0.030581\n",
            "Train Epoch: 8 [41600/60032 (69%)]\tLoss: 0.019743\n",
            "Train Epoch: 8 [42240/60032 (70%)]\tLoss: 0.005687\n",
            "Train Epoch: 8 [42880/60032 (71%)]\tLoss: 0.003541\n",
            "Train Epoch: 8 [43520/60032 (72%)]\tLoss: 0.006381\n",
            "Train Epoch: 8 [44160/60032 (74%)]\tLoss: 0.177847\n",
            "Train Epoch: 8 [44800/60032 (75%)]\tLoss: 0.075145\n",
            "Train Epoch: 8 [45440/60032 (76%)]\tLoss: 0.017340\n",
            "Train Epoch: 8 [46080/60032 (77%)]\tLoss: 0.025584\n",
            "Train Epoch: 8 [46720/60032 (78%)]\tLoss: 0.014807\n",
            "Train Epoch: 8 [47360/60032 (79%)]\tLoss: 0.020581\n",
            "Train Epoch: 8 [48000/60032 (80%)]\tLoss: 0.006628\n",
            "Train Epoch: 8 [48640/60032 (81%)]\tLoss: 0.022357\n",
            "Train Epoch: 8 [49280/60032 (82%)]\tLoss: 0.082077\n",
            "Train Epoch: 8 [49920/60032 (83%)]\tLoss: 0.009154\n",
            "Train Epoch: 8 [50560/60032 (84%)]\tLoss: 0.033577\n",
            "Train Epoch: 8 [51200/60032 (85%)]\tLoss: 0.014861\n",
            "Train Epoch: 8 [51840/60032 (86%)]\tLoss: 0.048815\n",
            "Train Epoch: 8 [52480/60032 (87%)]\tLoss: 0.009542\n",
            "Train Epoch: 8 [53120/60032 (88%)]\tLoss: 0.030500\n",
            "Train Epoch: 8 [53760/60032 (90%)]\tLoss: 0.010287\n",
            "Train Epoch: 8 [54400/60032 (91%)]\tLoss: 0.007172\n",
            "Train Epoch: 8 [55040/60032 (92%)]\tLoss: 0.005926\n",
            "Train Epoch: 8 [55680/60032 (93%)]\tLoss: 0.009491\n",
            "Train Epoch: 8 [56320/60032 (94%)]\tLoss: 0.110082\n",
            "Train Epoch: 8 [56960/60032 (95%)]\tLoss: 0.059694\n",
            "Train Epoch: 8 [57600/60032 (96%)]\tLoss: 0.137495\n",
            "Train Epoch: 8 [58240/60032 (97%)]\tLoss: 0.020265\n",
            "Train Epoch: 8 [58880/60032 (98%)]\tLoss: 0.065132\n",
            "Train Epoch: 8 [59520/60032 (99%)]\tLoss: 0.026818\n",
            "\n",
            "Test set: Average loss: 0.0494, Accuracy: 9837/10000 (98%)\n",
            "\n",
            "Train Epoch: 9 [0/60032 (0%)]\tLoss: 0.010621\n",
            "Train Epoch: 9 [640/60032 (1%)]\tLoss: 0.012325\n",
            "Train Epoch: 9 [1280/60032 (2%)]\tLoss: 0.059278\n",
            "Train Epoch: 9 [1920/60032 (3%)]\tLoss: 0.043002\n",
            "Train Epoch: 9 [2560/60032 (4%)]\tLoss: 0.019033\n",
            "Train Epoch: 9 [3200/60032 (5%)]\tLoss: 0.024187\n",
            "Train Epoch: 9 [3840/60032 (6%)]\tLoss: 0.014073\n",
            "Train Epoch: 9 [4480/60032 (7%)]\tLoss: 0.079503\n",
            "Train Epoch: 9 [5120/60032 (9%)]\tLoss: 0.027897\n",
            "Train Epoch: 9 [5760/60032 (10%)]\tLoss: 0.005316\n",
            "Train Epoch: 9 [6400/60032 (11%)]\tLoss: 0.088107\n",
            "Train Epoch: 9 [7040/60032 (12%)]\tLoss: 0.042549\n",
            "Train Epoch: 9 [7680/60032 (13%)]\tLoss: 0.030035\n",
            "Train Epoch: 9 [8320/60032 (14%)]\tLoss: 0.027933\n",
            "Train Epoch: 9 [8960/60032 (15%)]\tLoss: 0.019447\n",
            "Train Epoch: 9 [9600/60032 (16%)]\tLoss: 0.016735\n",
            "Train Epoch: 9 [10240/60032 (17%)]\tLoss: 0.029186\n",
            "Train Epoch: 9 [10880/60032 (18%)]\tLoss: 0.032936\n",
            "Train Epoch: 9 [11520/60032 (19%)]\tLoss: 0.005097\n",
            "Train Epoch: 9 [12160/60032 (20%)]\tLoss: 0.060850\n",
            "Train Epoch: 9 [12800/60032 (21%)]\tLoss: 0.019848\n",
            "Train Epoch: 9 [13440/60032 (22%)]\tLoss: 0.016519\n",
            "Train Epoch: 9 [14080/60032 (23%)]\tLoss: 0.006653\n",
            "Train Epoch: 9 [14720/60032 (25%)]\tLoss: 0.005615\n",
            "Train Epoch: 9 [15360/60032 (26%)]\tLoss: 0.022708\n",
            "Train Epoch: 9 [16000/60032 (27%)]\tLoss: 0.039429\n",
            "Train Epoch: 9 [16640/60032 (28%)]\tLoss: 0.006838\n",
            "Train Epoch: 9 [17280/60032 (29%)]\tLoss: 0.026179\n",
            "Train Epoch: 9 [17920/60032 (30%)]\tLoss: 0.035807\n",
            "Train Epoch: 9 [18560/60032 (31%)]\tLoss: 0.044132\n",
            "Train Epoch: 9 [19200/60032 (32%)]\tLoss: 0.031009\n",
            "Train Epoch: 9 [19840/60032 (33%)]\tLoss: 0.009406\n",
            "Train Epoch: 9 [20480/60032 (34%)]\tLoss: 0.013492\n",
            "Train Epoch: 9 [21120/60032 (35%)]\tLoss: 0.134016\n",
            "Train Epoch: 9 [21760/60032 (36%)]\tLoss: 0.185255\n",
            "Train Epoch: 9 [22400/60032 (37%)]\tLoss: 0.112837\n",
            "Train Epoch: 9 [23040/60032 (38%)]\tLoss: 0.012936\n",
            "Train Epoch: 9 [23680/60032 (39%)]\tLoss: 0.014675\n",
            "Train Epoch: 9 [24320/60032 (41%)]\tLoss: 0.039750\n",
            "Train Epoch: 9 [24960/60032 (42%)]\tLoss: 0.004119\n",
            "Train Epoch: 9 [25600/60032 (43%)]\tLoss: 0.046510\n",
            "Train Epoch: 9 [26240/60032 (44%)]\tLoss: 0.029199\n",
            "Train Epoch: 9 [26880/60032 (45%)]\tLoss: 0.005506\n",
            "Train Epoch: 9 [27520/60032 (46%)]\tLoss: 0.034031\n",
            "Train Epoch: 9 [28160/60032 (47%)]\tLoss: 0.015162\n",
            "Train Epoch: 9 [28800/60032 (48%)]\tLoss: 0.065811\n",
            "Train Epoch: 9 [29440/60032 (49%)]\tLoss: 0.035835\n",
            "Train Epoch: 9 [30080/60032 (50%)]\tLoss: 0.078650\n",
            "Train Epoch: 9 [30720/60032 (51%)]\tLoss: 0.031212\n",
            "Train Epoch: 9 [31360/60032 (52%)]\tLoss: 0.032026\n",
            "Train Epoch: 9 [32000/60032 (53%)]\tLoss: 0.075757\n",
            "Train Epoch: 9 [32640/60032 (54%)]\tLoss: 0.010626\n",
            "Train Epoch: 9 [33280/60032 (55%)]\tLoss: 0.019178\n",
            "Train Epoch: 9 [33920/60032 (57%)]\tLoss: 0.007946\n",
            "Train Epoch: 9 [34560/60032 (58%)]\tLoss: 0.011616\n",
            "Train Epoch: 9 [35200/60032 (59%)]\tLoss: 0.035803\n",
            "Train Epoch: 9 [35840/60032 (60%)]\tLoss: 0.044550\n",
            "Train Epoch: 9 [36480/60032 (61%)]\tLoss: 0.010985\n",
            "Train Epoch: 9 [37120/60032 (62%)]\tLoss: 0.008278\n",
            "Train Epoch: 9 [37760/60032 (63%)]\tLoss: 0.027753\n",
            "Train Epoch: 9 [38400/60032 (64%)]\tLoss: 0.054792\n",
            "Train Epoch: 9 [39040/60032 (65%)]\tLoss: 0.023498\n",
            "Train Epoch: 9 [39680/60032 (66%)]\tLoss: 0.018455\n",
            "Train Epoch: 9 [40320/60032 (67%)]\tLoss: 0.065544\n",
            "Train Epoch: 9 [40960/60032 (68%)]\tLoss: 0.079959\n",
            "Train Epoch: 9 [41600/60032 (69%)]\tLoss: 0.070368\n",
            "Train Epoch: 9 [42240/60032 (70%)]\tLoss: 0.055681\n",
            "Train Epoch: 9 [42880/60032 (71%)]\tLoss: 0.020708\n",
            "Train Epoch: 9 [43520/60032 (72%)]\tLoss: 0.007006\n",
            "Train Epoch: 9 [44160/60032 (74%)]\tLoss: 0.086073\n",
            "Train Epoch: 9 [44800/60032 (75%)]\tLoss: 0.332850\n",
            "Train Epoch: 9 [45440/60032 (76%)]\tLoss: 0.014474\n",
            "Train Epoch: 9 [46080/60032 (77%)]\tLoss: 0.011857\n",
            "Train Epoch: 9 [46720/60032 (78%)]\tLoss: 0.032056\n",
            "Train Epoch: 9 [47360/60032 (79%)]\tLoss: 0.017349\n",
            "Train Epoch: 9 [48000/60032 (80%)]\tLoss: 0.014579\n",
            "Train Epoch: 9 [48640/60032 (81%)]\tLoss: 0.059647\n",
            "Train Epoch: 9 [49280/60032 (82%)]\tLoss: 0.061094\n",
            "Train Epoch: 9 [49920/60032 (83%)]\tLoss: 0.070889\n",
            "Train Epoch: 9 [50560/60032 (84%)]\tLoss: 0.043354\n",
            "Train Epoch: 9 [51200/60032 (85%)]\tLoss: 0.018381\n",
            "Train Epoch: 9 [51840/60032 (86%)]\tLoss: 0.040405\n",
            "Train Epoch: 9 [52480/60032 (87%)]\tLoss: 0.024287\n",
            "Train Epoch: 9 [53120/60032 (88%)]\tLoss: 0.035443\n",
            "Train Epoch: 9 [53760/60032 (90%)]\tLoss: 0.025798\n",
            "Train Epoch: 9 [54400/60032 (91%)]\tLoss: 0.048381\n",
            "Train Epoch: 9 [55040/60032 (92%)]\tLoss: 0.043204\n",
            "Train Epoch: 9 [55680/60032 (93%)]\tLoss: 0.076210\n",
            "Train Epoch: 9 [56320/60032 (94%)]\tLoss: 0.024740\n",
            "Train Epoch: 9 [56960/60032 (95%)]\tLoss: 0.040662\n",
            "Train Epoch: 9 [57600/60032 (96%)]\tLoss: 0.011803\n",
            "Train Epoch: 9 [58240/60032 (97%)]\tLoss: 0.092465\n",
            "Train Epoch: 9 [58880/60032 (98%)]\tLoss: 0.009688\n",
            "Train Epoch: 9 [59520/60032 (99%)]\tLoss: 0.041764\n",
            "\n",
            "Test set: Average loss: 0.0417, Accuracy: 9868/10000 (99%)\n",
            "\n",
            "Train Epoch: 10 [0/60032 (0%)]\tLoss: 0.094765\n",
            "Train Epoch: 10 [640/60032 (1%)]\tLoss: 0.082583\n",
            "Train Epoch: 10 [1280/60032 (2%)]\tLoss: 0.005294\n",
            "Train Epoch: 10 [1920/60032 (3%)]\tLoss: 0.008171\n",
            "Train Epoch: 10 [2560/60032 (4%)]\tLoss: 0.067771\n",
            "Train Epoch: 10 [3200/60032 (5%)]\tLoss: 0.070737\n",
            "Train Epoch: 10 [3840/60032 (6%)]\tLoss: 0.025862\n",
            "Train Epoch: 10 [4480/60032 (7%)]\tLoss: 0.018455\n",
            "Train Epoch: 10 [5120/60032 (9%)]\tLoss: 0.048788\n",
            "Train Epoch: 10 [5760/60032 (10%)]\tLoss: 0.031475\n",
            "Train Epoch: 10 [6400/60032 (11%)]\tLoss: 0.011012\n",
            "Train Epoch: 10 [7040/60032 (12%)]\tLoss: 0.008812\n",
            "Train Epoch: 10 [7680/60032 (13%)]\tLoss: 0.012646\n",
            "Train Epoch: 10 [8320/60032 (14%)]\tLoss: 0.018136\n",
            "Train Epoch: 10 [8960/60032 (15%)]\tLoss: 0.023148\n",
            "Train Epoch: 10 [9600/60032 (16%)]\tLoss: 0.016829\n",
            "Train Epoch: 10 [10240/60032 (17%)]\tLoss: 0.011270\n",
            "Train Epoch: 10 [10880/60032 (18%)]\tLoss: 0.012318\n",
            "Train Epoch: 10 [11520/60032 (19%)]\tLoss: 0.027119\n",
            "Train Epoch: 10 [12160/60032 (20%)]\tLoss: 0.010711\n",
            "Train Epoch: 10 [12800/60032 (21%)]\tLoss: 0.010403\n",
            "Train Epoch: 10 [13440/60032 (22%)]\tLoss: 0.105502\n",
            "Train Epoch: 10 [14080/60032 (23%)]\tLoss: 0.048738\n",
            "Train Epoch: 10 [14720/60032 (25%)]\tLoss: 0.006938\n",
            "Train Epoch: 10 [15360/60032 (26%)]\tLoss: 0.022703\n",
            "Train Epoch: 10 [16000/60032 (27%)]\tLoss: 0.081032\n",
            "Train Epoch: 10 [16640/60032 (28%)]\tLoss: 0.023937\n",
            "Train Epoch: 10 [17280/60032 (29%)]\tLoss: 0.009296\n",
            "Train Epoch: 10 [17920/60032 (30%)]\tLoss: 0.011252\n",
            "Train Epoch: 10 [18560/60032 (31%)]\tLoss: 0.047148\n",
            "Train Epoch: 10 [19200/60032 (32%)]\tLoss: 0.006919\n",
            "Train Epoch: 10 [19840/60032 (33%)]\tLoss: 0.003251\n",
            "Train Epoch: 10 [20480/60032 (34%)]\tLoss: 0.003258\n",
            "Train Epoch: 10 [21120/60032 (35%)]\tLoss: 0.003240\n",
            "Train Epoch: 10 [21760/60032 (36%)]\tLoss: 0.025428\n",
            "Train Epoch: 10 [22400/60032 (37%)]\tLoss: 0.004467\n",
            "Train Epoch: 10 [23040/60032 (38%)]\tLoss: 0.008761\n",
            "Train Epoch: 10 [23680/60032 (39%)]\tLoss: 0.004094\n",
            "Train Epoch: 10 [24320/60032 (41%)]\tLoss: 0.006514\n",
            "Train Epoch: 10 [24960/60032 (42%)]\tLoss: 0.028930\n",
            "Train Epoch: 10 [25600/60032 (43%)]\tLoss: 0.003260\n",
            "Train Epoch: 10 [26240/60032 (44%)]\tLoss: 0.026411\n",
            "Train Epoch: 10 [26880/60032 (45%)]\tLoss: 0.009255\n",
            "Train Epoch: 10 [27520/60032 (46%)]\tLoss: 0.004142\n",
            "Train Epoch: 10 [28160/60032 (47%)]\tLoss: 0.036316\n",
            "Train Epoch: 10 [28800/60032 (48%)]\tLoss: 0.024693\n",
            "Train Epoch: 10 [29440/60032 (49%)]\tLoss: 0.031104\n",
            "Train Epoch: 10 [30080/60032 (50%)]\tLoss: 0.062771\n",
            "Train Epoch: 10 [30720/60032 (51%)]\tLoss: 0.049225\n",
            "Train Epoch: 10 [31360/60032 (52%)]\tLoss: 0.017717\n",
            "Train Epoch: 10 [32000/60032 (53%)]\tLoss: 0.031097\n",
            "Train Epoch: 10 [32640/60032 (54%)]\tLoss: 0.040401\n",
            "Train Epoch: 10 [33280/60032 (55%)]\tLoss: 0.075018\n",
            "Train Epoch: 10 [33920/60032 (57%)]\tLoss: 0.035999\n",
            "Train Epoch: 10 [34560/60032 (58%)]\tLoss: 0.012740\n",
            "Train Epoch: 10 [35200/60032 (59%)]\tLoss: 0.074812\n",
            "Train Epoch: 10 [35840/60032 (60%)]\tLoss: 0.052804\n",
            "Train Epoch: 10 [36480/60032 (61%)]\tLoss: 0.021391\n",
            "Train Epoch: 10 [37120/60032 (62%)]\tLoss: 0.098211\n",
            "Train Epoch: 10 [37760/60032 (63%)]\tLoss: 0.130933\n",
            "Train Epoch: 10 [38400/60032 (64%)]\tLoss: 0.005447\n",
            "Train Epoch: 10 [39040/60032 (65%)]\tLoss: 0.005451\n",
            "Train Epoch: 10 [39680/60032 (66%)]\tLoss: 0.071419\n",
            "Train Epoch: 10 [40320/60032 (67%)]\tLoss: 0.015662\n",
            "Train Epoch: 10 [40960/60032 (68%)]\tLoss: 0.008797\n",
            "Train Epoch: 10 [41600/60032 (69%)]\tLoss: 0.113671\n",
            "Train Epoch: 10 [42240/60032 (70%)]\tLoss: 0.003872\n",
            "Train Epoch: 10 [42880/60032 (71%)]\tLoss: 0.016065\n",
            "Train Epoch: 10 [43520/60032 (72%)]\tLoss: 0.007982\n",
            "Train Epoch: 10 [44160/60032 (74%)]\tLoss: 0.014755\n",
            "Train Epoch: 10 [44800/60032 (75%)]\tLoss: 0.015900\n",
            "Train Epoch: 10 [45440/60032 (76%)]\tLoss: 0.004931\n",
            "Train Epoch: 10 [46080/60032 (77%)]\tLoss: 0.054735\n",
            "Train Epoch: 10 [46720/60032 (78%)]\tLoss: 0.004763\n",
            "Train Epoch: 10 [47360/60032 (79%)]\tLoss: 0.012265\n",
            "Train Epoch: 10 [48000/60032 (80%)]\tLoss: 0.009359\n",
            "Train Epoch: 10 [48640/60032 (81%)]\tLoss: 0.003595\n",
            "Train Epoch: 10 [49280/60032 (82%)]\tLoss: 0.076608\n",
            "Train Epoch: 10 [49920/60032 (83%)]\tLoss: 0.008312\n",
            "Train Epoch: 10 [50560/60032 (84%)]\tLoss: 0.013318\n",
            "Train Epoch: 10 [51200/60032 (85%)]\tLoss: 0.034134\n",
            "Train Epoch: 10 [51840/60032 (86%)]\tLoss: 0.062374\n",
            "Train Epoch: 10 [52480/60032 (87%)]\tLoss: 0.045844\n",
            "Train Epoch: 10 [53120/60032 (88%)]\tLoss: 0.038278\n",
            "Train Epoch: 10 [53760/60032 (90%)]\tLoss: 0.050521\n",
            "Train Epoch: 10 [54400/60032 (91%)]\tLoss: 0.019187\n",
            "Train Epoch: 10 [55040/60032 (92%)]\tLoss: 0.060762\n",
            "Train Epoch: 10 [55680/60032 (93%)]\tLoss: 0.020366\n",
            "Train Epoch: 10 [56320/60032 (94%)]\tLoss: 0.055761\n",
            "Train Epoch: 10 [56960/60032 (95%)]\tLoss: 0.107053\n",
            "Train Epoch: 10 [57600/60032 (96%)]\tLoss: 0.002531\n",
            "Train Epoch: 10 [58240/60032 (97%)]\tLoss: 0.029917\n",
            "Train Epoch: 10 [58880/60032 (98%)]\tLoss: 0.039480\n",
            "Train Epoch: 10 [59520/60032 (99%)]\tLoss: 0.060281\n",
            "\n",
            "Test set: Average loss: 0.0358, Accuracy: 9878/10000 (99%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}