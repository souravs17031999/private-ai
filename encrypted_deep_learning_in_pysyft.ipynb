{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "encrypted_deep_learning_in_pysyft.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/souravs17031999/private-ai/blob/master/encrypted_deep_learning_in_pysyft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUhO_ChCRHqh",
        "colab_type": "text"
      },
      "source": [
        "# Project - XV\n",
        "## Objective : Part - I :To implement encrypted computations using pysyft  functions/methods.\n",
        "## Objective : Part - II :Create a encrypted database."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8jpg6sSn6J2",
        "colab_type": "text"
      },
      "source": [
        "### Part - I"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6aba4J1yV4t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "outputId": "dc7947f5-8db8-408c-8087-c8af1cf352e1"
      },
      "source": [
        "pip install syft"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: syft in /usr/local/lib/python3.6/dist-packages (0.1.21a1)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.3.0)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.0)\n",
            "Requirement already satisfied: websockets>=7.0 in /usr/local/lib/python3.6/dist-packages (from syft) (8.0)\n",
            "Requirement already satisfied: lz4>=2.1.6 in /usr/local/lib/python3.6/dist-packages (from syft) (2.1.10)\n",
            "Requirement already satisfied: websocket-client>=0.56.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.56.0)\n",
            "Requirement already satisfied: zstd>=1.4.0.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.16.4)\n",
            "Requirement already satisfied: tf-encrypted>=0.5.4 in /usr/local/lib/python3.6/dist-packages (from syft) (0.5.7)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.6/dist-packages (from syft) (0.21.2)\n",
            "Requirement already satisfied: tblib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0)\n",
            "Requirement already satisfied: Flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.1)\n",
            "Requirement already satisfied: msgpack>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from syft) (0.6.1)\n",
            "Requirement already satisfied: flask-socketio>=3.3.2 in /usr/local/lib/python3.6/dist-packages (from syft) (4.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->syft) (4.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted>=0.5.4->syft) (5.1.1)\n",
            "Requirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.0->syft) (0.13.2)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (2.10.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (7.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (0.15.4)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=1.0.2->syft) (1.1.0)\n",
            "Requirement already satisfied: python-socketio>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from flask-socketio>=3.3.2->syft) (4.2.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision>=0.3.0->syft) (0.46)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.1.7)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.7.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.11.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.7.1)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.33.4)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=1.0.2->syft) (1.1.1)\n",
            "Requirement already satisfied: python-engineio>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from python-socketio>=2.1.0->flask-socketio>=3.3.2->syft) (3.8.2.post1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvX8223WH4-_",
        "colab_type": "code",
        "outputId": "8667ad37-8296-46fa-cd59-192b641a503c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch as th\n",
        "import syft as sy\n",
        "\n",
        "hook = sy.TorchHook(th)\n",
        "from torch import nn, optim"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0719 09:08:56.250784 139956197033856 hook.py:98] Torch was already hooked... skipping hooking process\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdEFanI_RkrU",
        "colab_type": "text"
      },
      "source": [
        "We have created three virtual workers here , bob , alice and secure_worker to simulate our process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8v7z8JlKHN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bob = sy.VirtualWorker(hook, id = \"bob\").add_worker(sy.local_worker)\n",
        "alice = sy.VirtualWorker(hook, id = \"alice\").add_worker(sy.local_worker)\n",
        "secure_worker = sy.VirtualWorker(hook, id = \"secure_worker\").add_worker(sy.local_worker)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t31_W7kLSJNu",
        "colab_type": "text"
      },
      "source": [
        "Let's create our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trJRhhyZR6cG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = th.tensor([1,2,3,4])\n",
        "y = th.tensor([2,-1,1,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl4pkv3jSLht",
        "colab_type": "text"
      },
      "source": [
        "Let's say we firstly wanted to implement the secret sharing process so that there are randomly generated numbers , and since crypto_provider here is used only for system efficiency for deep learning systems when generating randomly large numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpBG1MIDL13T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = x.share(bob, alice, crypto_provider = secure_worker)\n",
        "y = y.share(bob, alice, crypto_provider = secure_worker)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K403hIg2VmZB",
        "colab_type": "text"
      },
      "source": [
        "We can see that , there are pointer tensors created for x and y for bob and alice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWBSEqQKSCzL",
        "colab_type": "code",
        "outputId": "867be8cc-cc71-4755-e591-7c353cc33112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[AdditiveSharingTensor]\n",
              "\t-> (Wrapper)>[PointerTensor | me:30222100825 -> bob:18842362774]\n",
              "\t-> (Wrapper)>[PointerTensor | me:62987771405 -> alice:73491776140]\n",
              "\t*crypto provider: secure_worker*"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bKkHDdwSEWl",
        "colab_type": "code",
        "outputId": "c7b9da69-2358-40fb-ebee-a1e51e075085",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "y"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>[AdditiveSharingTensor]\n",
              "\t-> (Wrapper)>[PointerTensor | me:28378567834 -> bob:89511740206]\n",
              "\t-> (Wrapper)>[PointerTensor | me:91296390059 -> alice:23058094486]\n",
              "\t*crypto provider: secure_worker*"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwgn7IwGTfFY",
        "colab_type": "text"
      },
      "source": [
        "Here , we can see randomly generated numbers for both tensors x, y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU8oqH1uSvsn",
        "colab_type": "code",
        "outputId": "a0e0348e-ec63-49c5-c2c2-c14675a7fe82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "bob._objects "
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{18842362774: tensor([ 682205084225130468, 4246699920549455353, 4285627654817167306,\n",
              "         3055557465183765950]),\n",
              " 89511740206: tensor([1435455331595824286, 4293133921423497963, 2005778343057245443,\n",
              "         2478799071062201470])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AidAXMjPVJHG",
        "colab_type": "code",
        "outputId": "30ffafb0-97ab-4a6c-95f0-34a8b03a3ee3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "alice._objects\n"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{23058094486: tensor([-1435455331595824284, -4293133921423497964, -2005778343057245442,\n",
              "         -2478799071062201470]),\n",
              " 73491776140: tensor([ -682205084225130467, -4246699920549455351, -4285627654817167303,\n",
              "         -3055557465183765946])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6VRJO7xVP10",
        "colab_type": "code",
        "outputId": "10b221e2-328d-4307-9a37-d958eb2e7153",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "secure_worker._objects"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rd1F6mTrSlW1",
        "colab_type": "text"
      },
      "source": [
        "We will now start implementing operations using pysyft."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCHct8ZiSjxP",
        "colab_type": "code",
        "outputId": "d406a727-7639-4160-8e36-5c136ac2d108",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = x + y\n",
        "z\n",
        "z.get()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 1, 4, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsJ_EpRIVe9w",
        "colab_type": "code",
        "outputId": "705fcd1f-4da4-406c-f6a0-bc0ba43dc9f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = x - y\n",
        "z.get()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1,  3,  2,  4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SUSQEJSVhAL",
        "colab_type": "code",
        "outputId": "7cc4996a-11fd-48fe-8183-f98031786e63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = x > y\n",
        "z.get()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTZf3Sh3V9DA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z = x < y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8snc2TxV-dg",
        "colab_type": "code",
        "outputId": "f32d1730-1ca3-4056-8759-00fdff6568cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = x == y\n",
        "z.get()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmEzPKi9WBQr",
        "colab_type": "code",
        "outputId": "7d0a7d12-4721-4038-e262-44ff2054adff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = x * y\n",
        "z.get()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2, -2,  3,  0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sExxLNsom36",
        "colab_type": "text"
      },
      "source": [
        "We can't just only this for integers , but also for floating numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIr4e900or3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = th.tensor([1,2,3,4])\n",
        "y = th.tensor([2,-1,1,0])\n",
        "\n",
        "x = x.fix_precision().share(bob, alice, crypto_provider=secure_worker)\n",
        "y = y.fix_precision().share(bob, alice, crypto_provider=secure_worker)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "El-8wpNlo10W",
        "colab_type": "code",
        "outputId": "573b458c-20c5-47fc-f3d1-1446825be193",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Wrapper)>FixedPrecisionTensor>(Wrapper)>[AdditiveSharingTensor]\n",
              "\t-> (Wrapper)>[PointerTensor | me:30138995206 -> bob:61867297547]\n",
              "\t-> (Wrapper)>[PointerTensor | me:20360962498 -> alice:95074218914]\n",
              "\t*crypto provider: secure_worker*"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8sUbu1so8Tr",
        "colab_type": "code",
        "outputId": "5da6569f-f9bf-44e4-fc0a-702eeeef61ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = x + y\n",
        "z.get().float_precision()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 1., 4., 4.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvUOaFMMpAxz",
        "colab_type": "code",
        "outputId": "2643cf87-e724-4c8c-af60-70c686bbb16e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = x - y\n",
        "z.get().float_precision()"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.,  3.,  2.,  4.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyFAHCZRpBX7",
        "colab_type": "code",
        "outputId": "17d7ef9c-4424-494d-d5b5-a2ff1fc11e55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = x * y\n",
        "z.get().float_precision()"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 2., -2.,  3.,  0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiqNbSn0pEJA",
        "colab_type": "code",
        "outputId": "600dd1e3-c931-4714-8170-065c92401fbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = x > y\n",
        "z.get().float_precision()"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqVW3UK4pGau",
        "colab_type": "code",
        "outputId": "d64891c5-58b5-41d3-f9d5-0880f2dc664f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = x < y\n",
        "z.get().float_precision()"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMFnbRuKpHuu",
        "colab_type": "code",
        "outputId": "63b95075-c417-4683-8612-1e1778964afa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "z = x == y\n",
        "z.get().float_precision()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxqnoKDMn2wg",
        "colab_type": "text"
      },
      "source": [
        "### Part -2 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgdI37NzobF8",
        "colab_type": "text"
      },
      "source": [
        "## Encrypted Database\n",
        "### The objective to build a encrypted database with all the values represented in either some index mapped or one hot encoded so that datbase managers do not know what goes inside and what comes out as we have to encrypt all operations on query as well.\n",
        "### The database is stored in the form of keys and values pair."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c70-mD3Pvp0N",
        "colab_type": "text"
      },
      "source": [
        "So , first of all , let's get started by creating a lookup table , something sort of dictioneries mapping each indices to some chars and characters (will be used when querying the db) to some index."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9Vz-GiHXAM-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvbmtMirv5Hf",
        "colab_type": "text"
      },
      "source": [
        "Creating two dictioners for above mentioned goal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMFkcf7JvAKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char2index = {} # maps each chars to unique index\n",
        "index2char = {} # maps each index to some unique char that we have chosen below"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC0TUGQLvH8o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "53403562-a2c3-45bd-a6aa-5e600e2e77a2"
      },
      "source": [
        "' ' + string.ascii_lowercase + '0123456789' + string.punctuation"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Tq44Fm6vVTY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i, char in enumerate(' ' + string.ascii_lowercase + '0123456789' + string.punctuation):\n",
        "  char2index[char] = i\n",
        "  index2char[i] = char"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ClqcXHmviP5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "01e8a4b3-41c9-4fbb-e560-08baef930bb1"
      },
      "source": [
        "char2index"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 0,\n",
              " '!': 37,\n",
              " '\"': 38,\n",
              " '#': 39,\n",
              " '$': 40,\n",
              " '%': 41,\n",
              " '&': 42,\n",
              " \"'\": 43,\n",
              " '(': 44,\n",
              " ')': 45,\n",
              " '*': 46,\n",
              " '+': 47,\n",
              " ',': 48,\n",
              " '-': 49,\n",
              " '.': 50,\n",
              " '/': 51,\n",
              " '0': 27,\n",
              " '1': 28,\n",
              " '2': 29,\n",
              " '3': 30,\n",
              " '4': 31,\n",
              " '5': 32,\n",
              " '6': 33,\n",
              " '7': 34,\n",
              " '8': 35,\n",
              " '9': 36,\n",
              " ':': 52,\n",
              " ';': 53,\n",
              " '<': 54,\n",
              " '=': 55,\n",
              " '>': 56,\n",
              " '?': 57,\n",
              " '@': 58,\n",
              " '[': 59,\n",
              " '\\\\': 60,\n",
              " ']': 61,\n",
              " '^': 62,\n",
              " '_': 63,\n",
              " '`': 64,\n",
              " 'a': 1,\n",
              " 'b': 2,\n",
              " 'c': 3,\n",
              " 'd': 4,\n",
              " 'e': 5,\n",
              " 'f': 6,\n",
              " 'g': 7,\n",
              " 'h': 8,\n",
              " 'i': 9,\n",
              " 'j': 10,\n",
              " 'k': 11,\n",
              " 'l': 12,\n",
              " 'm': 13,\n",
              " 'n': 14,\n",
              " 'o': 15,\n",
              " 'p': 16,\n",
              " 'q': 17,\n",
              " 'r': 18,\n",
              " 's': 19,\n",
              " 't': 20,\n",
              " 'u': 21,\n",
              " 'v': 22,\n",
              " 'w': 23,\n",
              " 'x': 24,\n",
              " 'y': 25,\n",
              " 'z': 26,\n",
              " '{': 65,\n",
              " '|': 66,\n",
              " '}': 67,\n",
              " '~': 68}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4dyHk7fvlst",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "af9dfc32-5c8f-429c-b81f-293666030138"
      },
      "source": [
        "index2char"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: ' ',\n",
              " 1: 'a',\n",
              " 2: 'b',\n",
              " 3: 'c',\n",
              " 4: 'd',\n",
              " 5: 'e',\n",
              " 6: 'f',\n",
              " 7: 'g',\n",
              " 8: 'h',\n",
              " 9: 'i',\n",
              " 10: 'j',\n",
              " 11: 'k',\n",
              " 12: 'l',\n",
              " 13: 'm',\n",
              " 14: 'n',\n",
              " 15: 'o',\n",
              " 16: 'p',\n",
              " 17: 'q',\n",
              " 18: 'r',\n",
              " 19: 's',\n",
              " 20: 't',\n",
              " 21: 'u',\n",
              " 22: 'v',\n",
              " 23: 'w',\n",
              " 24: 'x',\n",
              " 25: 'y',\n",
              " 26: 'z',\n",
              " 27: '0',\n",
              " 28: '1',\n",
              " 29: '2',\n",
              " 30: '3',\n",
              " 31: '4',\n",
              " 32: '5',\n",
              " 33: '6',\n",
              " 34: '7',\n",
              " 35: '8',\n",
              " 36: '9',\n",
              " 37: '!',\n",
              " 38: '\"',\n",
              " 39: '#',\n",
              " 40: '$',\n",
              " 41: '%',\n",
              " 42: '&',\n",
              " 43: \"'\",\n",
              " 44: '(',\n",
              " 45: ')',\n",
              " 46: '*',\n",
              " 47: '+',\n",
              " 48: ',',\n",
              " 49: '-',\n",
              " 50: '.',\n",
              " 51: '/',\n",
              " 52: ':',\n",
              " 53: ';',\n",
              " 54: '<',\n",
              " 55: '=',\n",
              " 56: '>',\n",
              " 57: '?',\n",
              " 58: '@',\n",
              " 59: '[',\n",
              " 60: '\\\\',\n",
              " 61: ']',\n",
              " 62: '^',\n",
              " 63: '_',\n",
              " 64: '`',\n",
              " 65: '{',\n",
              " 66: '|',\n",
              " 67: '}',\n",
              " 68: '~'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk7yx4YgDvgH",
        "colab_type": "text"
      },
      "source": [
        "so we are here  , creating a function for changing every char in the given string to mapped index values and return that list as a tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2s1K3wNYwFDM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def string2values(str_input, max_length = 8):\n",
        "  \n",
        "  str_input = str_input[:max_length].lower()  # if the string length is more than max_length , then trim it to the fixed max_length\n",
        "   \n",
        "  if(len(str_input) < max_length):\n",
        "    str_input = str_input + \".\" * (max_length - len(str_input))  # if the string length is less than fixed max length then pad it with that number of zeroes\n",
        "  \n",
        "  values = []\n",
        "  for char in str_input:\n",
        "    values.append(char2index[char])  # appending every char mapped to index values to the list\n",
        "  return th.tensor(values).long      # returning list as a tensor so that we can encrypt the computations  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeWVMMPkxnle",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e3f18e6-2453-4a61-82c9-7316737fbc77"
      },
      "source": [
        "string2values(\"sourav\")"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method TorchHook.get_hooked_method.<locals>.overloaded_native_method of tensor([19, 15, 21, 18,  1, 22, 50, 50])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JszKQD9FbH-",
        "colab_type": "text"
      },
      "source": [
        "Here  , we create a function to one hot encoding so that we represent each char as a one hot tensor "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pwnCXly-BnF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def onehot(index, length):\n",
        "  vect = th.zeros(length).long()  # creating zeroes filled tensor \n",
        "  vect[index] = 1  # putting 1 at given index \n",
        "  return vect  # returning one hot encoded tensor\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7Trzsxn-csO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f3c8f50-8fba-4e2c-c95a-27630fb43180"
      },
      "source": [
        "onehot(1, 8)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c4iGwj3Fmn7",
        "colab_type": "text"
      },
      "source": [
        "here , we are creating  a function which takes str_input as input value , and change it into one hot encoding of tensors , and then unsqueezing it so that we have a matrix of 2-d of shape 8, 69 so that we have a whole list of eevry character of string as a one hot encoded in the tensor form."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsFjfIxw-jCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def string2one_hot_matrix(str_input, max_length=8):\n",
        "  str_input = str_input[:max_length].lower()\n",
        "  \n",
        "  if(len(str_input) < max_length):\n",
        "    str_input = str_input + \".\" * (max_length - len(str_input))\n",
        "  \n",
        "  char_vectors = list()\n",
        "  for char in str_input:\n",
        "    char_v = onehot(char2index[char], len(char2index)).unsqueeze(0)  # creating one hot encoding for each char and appending to list\n",
        "    char_vectors.append(char_v)\n",
        "  return th.cat(char_vectors, dim = 0)  # returning a whole matrix of one hot encoded tensors for each characters in the string given as input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyBHezROBDfp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "matrix = string2one_hot_matrix('sourav')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRxMf_UPBU48",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42606489-b59f-4633-b6e9-5ee445a6377a"
      },
      "source": [
        "matrix.shape"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 69])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd0BPncrOpJq",
        "colab_type": "text"
      },
      "source": [
        "Now we are interested in findind if queries match the required keys that will be storing in the database , so for that we apply a very clever technique that firstly we get onc hot encoded values of both strings to be matched as a matrix , then we multiply corresponding values and sum them , so that we get exactly how many of them matched , as those matching will be 1's and not matching will be 0's.\n",
        "Now , after this , we mutiply all these values in the above tensor , so that if the strings matched completely , then it will return the tensor will all 1's and multiplying these will also return '1' which is our required result and if it doesn't match completely (if a single char also doesn't matches) then it will return somewhere 0 in the above made tensor and then multiplying these will get us '0' which is also our desired result in this case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a1zv8p_CDae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def strings_equal(str_a, str_b):\n",
        "  vect = (str_a * str_b).sum(1)  # multiplying both one-hot enocoded matrices and summing over them across a dimension \n",
        "  x = vect[0] # assinging x the first value of vect \n",
        "  for i in range(vect.shape[0] - 1): \n",
        "    x *= vect[i + 1]  # simply multiplying all the values in the tensor of vect \n",
        "  return x  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcfsG7U_Npoe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27d6e686-0d58-4e8a-9a35-cf989e473a3a"
      },
      "source": [
        "strings_equal(string2one_hot_matrix(\"soura\"), string2one_hot_matrix(\"sourav\"))"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taTPHUPIS4sJ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Fy3or0KS72K",
        "colab_type": "text"
      },
      "source": [
        "Let's now enter something into database in the form of key value pairs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vS_In239OQog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keys = list()\n",
        "values = list()\n",
        "\n",
        "keys.append(string2one_hot_matrix(\"key1\"))\n",
        "keys.append(string2one_hot_matrix(\"key2\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrwYJNbLVAWY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "outputId": "19e8448f-8fbc-41d0-a87c-69b23d6d0a4e"
      },
      "source": [
        "keys"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
              " tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfAPhcQ5VE8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "values.append(string2values(\"value1\"))\n",
        "values.append(string2values(\"value2\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJezsOYjVNdM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3fc55f8a-c1fb-4a95-e22a-22475437a256"
      },
      "source": [
        "values"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<bound method TorchHook.get_hooked_method.<locals>.overloaded_native_method of tensor([22,  1, 12, 21,  5, 28, 50, 50])>,\n",
              " <bound method TorchHook.get_hooked_method.<locals>.overloaded_native_method of tensor([22,  1, 12, 21,  5, 29, 50, 50])>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U--5UGfWcNc",
        "colab_type": "text"
      },
      "source": [
        "We are now interested in getting a query from user and checking whether any of our keys match with the query key so that we can return appropriate values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf9i49KVfYHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "query_str = \"key2\"\n",
        "query_matrix = string2one_hot_matrix(query_str)\n",
        "\n",
        "key_matches = list()\n",
        "for key in keys:\n",
        "  key_match = strings_equal(key, query_matrix)\n",
        "  key_matches.append(key_match)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmzbfMgSfdwJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "518585e7-8463-4710-ea04-1ad95953b463"
      },
      "source": [
        "print(key_matches)\n",
        "print(values)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor(0), tensor(1)]\n",
            "[<bound method TorchHook.get_hooked_method.<locals>.overloaded_native_method of tensor([22,  1, 12, 21,  5, 28, 50, 50])>, <bound method TorchHook.get_hooked_method.<locals>.overloaded_native_method of tensor([22,  1, 12, 21,  5, 29, 50, 50])>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0Zo8pfGWkpy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def values2string(input_values):\n",
        "    s = \"\"\n",
        "    for value in input_values:\n",
        "        s += index2char[int(value)]\n",
        "    return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDMnNiFYgShO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf6e88b9-1ac1-4920-8075-7ac1676bda03"
      },
      "source": [
        "p = string2values(\"sourav\")\n",
        "print(p)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method TorchHook.get_hooked_method.<locals>.overloaded_native_method of tensor([19, 15, 21, 18,  1, 22, 50, 50])>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdZrTGK0hXCw",
        "colab_type": "text"
      },
      "source": [
        "Let's now make a class and put them all inside one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0prdGmwh25l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def string2values(str_input, max_len=8):\n",
        "\n",
        "    str_input = str_input[:max_len].lower()\n",
        "\n",
        "    # pad strings shorter than max len\n",
        "    if(len(str_input) < max_len):\n",
        "        str_input = str_input + \".\" * (max_len - len(str_input))\n",
        "\n",
        "    values = list()\n",
        "    for char in str_input:\n",
        "        values.append(char2index[char])\n",
        "\n",
        "    return th.tensor(values).long()\n",
        "\n",
        "def values2string(input_values):\n",
        "    s = \"\"\n",
        "    for value in input_values:\n",
        "        s += index2char[int(value)]\n",
        "    return s\n",
        "\n",
        "def strings_equal(str_a, str_b):\n",
        "\n",
        "    vect = (str_a * str_b).sum(1)\n",
        "\n",
        "    x = vect[0]\n",
        "\n",
        "    for i in range(vect.shape[0] - 1):\n",
        "        x = x * vect[i + 1]    \n",
        "\n",
        "    return x\n",
        "\n",
        "def one_hot(index, length):\n",
        "    vect = th.zeros(length).long()\n",
        "    vect[index] = 1\n",
        "    return vect\n",
        "def string2one_hot_matrix(str_input, max_len=8):\n",
        "\n",
        "    str_input = str_input[:max_len].lower()\n",
        "\n",
        "    # pad strings shorter than max len\n",
        "    if(len(str_input) < max_len):\n",
        "        str_input = str_input + \".\" * (max_len - len(str_input))\n",
        "\n",
        "    char_vectors = list()\n",
        "    for char in str_input:\n",
        "        char_v = one_hot(char2index[char], len(char2index)).unsqueeze(0)\n",
        "        char_vectors.append(char_v)\n",
        "        \n",
        "    return th.cat(char_vectors, dim=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9GrD0kphUHi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncryptedDB():\n",
        "    \n",
        "    def __init__(self, *owners, max_key_len=8, max_val_len=8):\n",
        "        self.max_key_len = max_key_len\n",
        "        self.max_val_len = max_val_len\n",
        "        \n",
        "        self.keys = list()\n",
        "        self.values = list()\n",
        "        self.owners = owners\n",
        "        \n",
        "    def add_entry(self, key, value):\n",
        "        key = string2one_hot_matrix(key)\n",
        "        key = key.share(*self.owners)\n",
        "        self.keys.append(key)\n",
        "        \n",
        "        value = string2values(value, max_len=self.max_val_len)\n",
        "        value = value.share(*self.owners)\n",
        "        self.values.append(value)\n",
        "        \n",
        "    def query(self, query_str):\n",
        "        query_matrix = string2one_hot_matrix(query_str)\n",
        "        \n",
        "        query_matrix = query_matrix.share(*self.owners)\n",
        "\n",
        "        key_matches = list()\n",
        "        for key in self.keys:\n",
        "\n",
        "            key_match = strings_equal(key, query_matrix)\n",
        "            key_matches.append(key_match)\n",
        "\n",
        "        result = self.values[0] * key_matches[0]\n",
        "\n",
        "        for i in range(len(self.values) - 1):\n",
        "            result += self.values[i+1] * key_matches[i+1]\n",
        "            \n",
        "        result = result.get()\n",
        "\n",
        "        return values2string(result).replace(\".\",\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KD77TBpkhhGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "db = EncryptedDB(bob, alice, secure_worker, max_val_len=256) # the db has joint ownership of these workers but they will not be able to see whats inside\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cX3DnmKMhjf3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9034a679-eaf7-477e-bc1c-0b816a64f1f2"
      },
      "source": [
        "db.add_entry(\"Bob\",\"(123) 456 7890\")\n",
        "db.add_entry(\"Bill\", \"(234) 567 8901\")\n",
        "db.add_entry(\"Sam\",\"(345) 678 9012\")\n",
        "db.add_entry(\"Key\",\"really big json value\")\n",
        "\n",
        "db.query(\"Bob\")"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(123) 456 7890'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    }
  ]
}